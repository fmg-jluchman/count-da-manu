\documentclass[doc]{apa7}
\usepackage[T1]{fontenc}
\usepackage[american]{babel}
\usepackage[style=apa,backend=biber]{biblatex}
\usepackage{csquotes}
\addbibresource{CountDominance.bib}

\title{Relative importance analysis for count regression models}
\author{Joseph N. Luchman}
\affiliation{Fors Marsh}
\leftheader{Luchman}
\shorttitle{Count Model Dominance}

\abstract{
	Count variables are common in organizational science as an outcome. Count regression models (CRMs), such as Poisson regression, are recommended as methods to analyze count variables but can be challenging to interpret given their non-linear functional form. I recommend relative importance analysis as a method to use in interpreting CRM results. This work extends on past research by describing an approach to determining the importance of independent variables in CRMs using dominance analysis (DA). In this manuscript, I review DA as a relative importance method, recommend an $R^2$ to use with CRM-based DA, and outline the results of an analysis with simulated data that uses the recommended methodology. This work contributes to the literature by extending DA to CRMs and provides a thoroughly documented example analysis that researchers can use to implement the methodology in their research.
}

\keywords{Dominance Analysis, Relative Importance, Poisson Regression, R-square, Negative Binomial Regression, Count Data}
	
\begin{document}

\maketitle

	Organizational science often uses how many times a behavior is observed as an outcome to answer research questions. 
	Such behavior counts arise from many different sources at the organization- and individual-level of aggregation.
	Organization-level behavior counts used in the literature include the number of organizations adopting a specific practice in a week \parencite{naumovska2021strength} and number of divestitures organizations make in a year \parencite{bettinazzi2021stakeholder}. 
	Individual-level behavior counts used in the literature include the number of scientific articles published in a year by an academic \parencite{rotolo2013does} or number of errors that resulted in an accident in the last three months among medical doctors \parencite{naveh2015active}.
	Behavior counts such as the above examples are valuable outcomes given that organizational science concepts are often defined terms of behavior \parencite[e.g., job performance;][]{motowidlo2003job} and strategies to validate outcomes often use observable behavior as an outcome \parencite[e.g., criterion-oriented validity;][]{cronbach1955construct}.
	
	The conceptual value of behavior counts as outcomes aside, data analysis with behavior counts as a dependent variable/DV require the use of specialized tools.
	The recommended data analysis strategy with behavior counts uses regression models designed for non-negative integer or count distributions \parencite[e.g.,][]{blevins2015count}.
	These count regression models/CRMs include the Poisson regression/PR and negative Binomial regression/NBR models.
	Both PR and NBR are commonly used in the organizational science literature and implemented in many data analytic software environments.
	
	CRMs are generalized linear models that mathematically transform the predictive equation to ensure that predicted values stay in the range of the DV.
	CRMs use an exponential or log-linear transformation that has the form $y = e^{\beta}$. 
	Thus the predictive equation represented by $\beta$ requires back-transformation using a natural logarithm in order to obtain a predicted count value.
	This log-linear transformation ensures that predicted values from $\beta$ can take on any number in the real number line yet, when back-transformed into predicted counts, will have a lower bound of 0.
	
	The log-linear predictive equations and coefficients CRMs estimate are challenging to interpret directly.
	Log-linear CRM coefficients are challenging to interpret because they describe how the natural logarithm of the DV changes given a 1 unit change to an independent variable/IV. 
	When back-translated through an exponential function, CRM coefficients are known as incidence rate ratios and describe the percentage change in the DV per unit change to the IV.
	Importantly, the percentage change described by CRM coefficients makes the count values produced by those changes relative to where they began.
	For example, a CRM coefficient does not differentiate between a change from 1 predicted behavior to 2 and 5 predicted behaviors to 10. 
	Despite the noteworthy difference in the absolute number of behaviors in both examples, each describe a 100\% increase in the count DV value.
		
	Model post-estimation methods such as graphing estimated marginal means are useful interpretive tools for log-linear CRMs to better contextualize the logarithmic predicted values they produce.
	Another increasingly common model post-estimation tool used to contextualize model predictions are relative importance analysis methods \parencite{tonidandel2011relative}. 
	Relative importance analysis methods focus on how different IVs in the model contribute to the $R^2$ as computed by methods such as dominance analysis/DA \parencite{azen2003dominance}.
	
	To date, published methodological work has extended DA from the linear regression model/LRM on which it was originally developed, to generalized linear models including binary \parencite{azen2009using}, ordered, and multinomial logit models \parencite{luchman2014relative}.	
	This work extends DA to CRMs and makes two contributions to the literature.
	This work first reviews DA as a relative importance methodology, recommends using a specific pseudo-$R^2$ statistic for CRM-based DA, and implements multiple data analytic examples of DA with that statistic.
	The pseudo-$R^2$ chosen for CRM-based DA is a direct generalization of the explained variance $R^2$ in the LRM to generalized linear models based on model deviance.
	The data analytic examples then use this deviance-based pseudo-$R^2$ as the fit statistic in a series of DA computations with simulated Poisson and negative Binomial distributed data.

	Second, this work extends on that of Blevins, Tsang, and Spain \parencite*{blevins2015count}'s review and recommendations for the use of CRMs in organizational science. 
	Blevins et al. discuss the extent of CRM use in the organizational science literature, describe model and analytic details about the PR and NBR models, and provide a flowchart that researchers can use to identify which CRM might be best to choose for their data analysis.
	In this work, I extend on their review to add an in-depth discussion of DA and its role as a post-estimation methodology.
	DA extends on the interpretation of coefficients to describe how the coefficients, when applied to the observed data, improve model-to-data fit in predicting the count DV.

	I begin the manuscript with a detailed discussion of the conceptual background of DA--the relative importance analysis method most applicable to CRMs.	
 	Here I discuss the different levels of dominance between two IVs as defined by DA, how these levels are determined in the data, and what this level of dominance means in terms of the importance of any IV in the model.
	The conceptual discussion of DA is followed by a more focused discussion where I apply DA to CRMs.
	The goal of the focused CRM-based DA discussion is to recommend a model fit statistic for use in dominance designations.
	In the third section, I apply the topics discussed in the previous two sections in a detailed PR-based DA using simulated data designed to be useful in illustrating key CRM-based DA concepts.
		
\section{Dominance Analysis: A Unique Relative Importance Analysis Method}

	Research methodologists and statisticians have used many methods over the years to determine how important an IV is in a LRM \parencite[see reviews in][]{gromping2007estimators, johnson2004history}.
	Importance methods have included the correlation between the IV and DV, an IV's standardized regression coefficient, as well as the increment to the $R^2$ an IV makes when predicting the DV.
	These methods, however informative in specific circumstances, are not considered to be useful as importance metrics as they fail to simultaneously account for the IV's bivariate and multivariate (i.e., controlling for other IVs) relationships with the DV \parencite{johnson2004history}.
	Accommodating both bi- and multivariate relationships is important in determining importance as, for most statistical models, the order in which IVs are included in the model is arbitrary yet IV inclusion order fundamentally affects the conclusions drawn.
	Hence, it is essential to use importance methods that produce results that are independent of inclusion order.
	
	One importance method that is independent of ordering and has enjoyed favorable reviews in the methodology community is DA.
	DA was originally developed as a method for determining IV importance for the LRM by Budescu \parencite*{budescu1993dominance}.
	DA extended on past importance methods by defining importance in terms of pairwise IV comparisons across multiple sub-model $R^2$ values.
	Sub-model $R^2$ values are those computed by re-fitting the model to the data with some subset of all the IVs.
	In a model with $p$ IVs there are a total of $2^p$ sub-models including the full model with all $p$ IVs and the null model with none of the IVs (i.e., an intercept-only model which always produces an $R^2$ value of 0 and is often omitted).
	DA achieves order independence by comparing the pair of focal IVs' $R^2$ values across all possible sets of equivalent non-focal IV sub-models. 
	A non-focal IV sub-model is a sub-model that contains a distinct subset of the $p - 2$ non-focal IVs (which can be the null set, $\emptyset$, of no other non-focal IVs).	
	In this way, the dominance comparisons produced by DA do not depend on the order of IV inclusion and require that one focal IV obtain higher $R^2$ values than the other focal IV irrespective of which non-focal IVs are included, or not, in the sub-model.
	
	As an example of how the dominance comparison is implemented, consider a model with 4 IVs: $IV_x$, $IV_z$, $IV_w$ and $IV_v$ predicting $Y$.
	If the comparison pair for the dominance analysis was focusing on $IV_x$ versus $IV_z$, there would be a total of four possible $R^2$ comparisons, each of which is reported below in Table \ref{tab:exdom}.
	In each comparison, the subscripted model indicates the LRM prediction equation in symbolic form.
	The terms in braces represent the non-focal IV subset for the comparison.
	$IV_x$ dominates $IV_z$ only when all the sub-model $R^2$ values that include $IV_x$ are greater than the sub-model $R^2$ values that include $IV_z$.
	The dominance comparisons described in this section have, more recently, been named complete dominance and have been recognized as the most stringent, or hardest to achieve, dominance designation that an IV can obtain over another IV in a series of three possible dominance designations between IV pairs \parencite{azen2003dominance}.	

		\begin{table}[h!]
			\centering
			\caption{\centering Example Dominance Comparisons}
			\begin{tabular}{ l | l l }
				
				& Sub-model with $IV_x$ & Sub-model with $IV_z$ \\
				\hline
				Across null set/no other IVs & $R^2_{Y \sim IV_x + \{\emptyset\}}$ & $R^2_{Y \sim IV_z+ \{\emptyset\} }$ \\
				Comparing across $IV_w$ & $R^2_{Y \sim IV_x + \{IV_w\}}$ & $R^2_{Y \sim IV_z + \{IV_w\}}$ \\
				Comparing across $IV_v$ & $R^2_{Y \sim IV_x + \{IV_v\}}$ & $R^2_{Y \sim IV_z + \{IV_w\}}$ \\
				Comparing across both $IV_w$ and $IV_v$ & $R^2_{Y \sim IV_x + \{IV_w + IV_v\}}$ & $R^2_{Y \sim IV_z + \{IV_w + IV_v\}}$ \\
				\hline
		\end{tabular}
		\label{tab:exdom}
	\end{table}
	
	\subsection{Complete Dominance}
	
	Complete dominance is the most stringent of the dominance designations as it is a difficult designation for an IV to achieve over another.
	Complete dominance is difficult to achieve as it involves direct comparisons between IV pairs across multiple sub-model $R^2$ values and is non-compensatory; all sub-model $R^2$ value comparisons must show that one IV has a larger value than the other IV or the designation will fail to be achieved.
	
	The process for determining complete dominance between a pair of IVs, for example $IV_x$ and $IV_z$, with an arbitrary number of non-focal IVs in the model ($p - 2$) is defined as:
	
	\begin{equation}
		IV_x \, D \, IV_z \quad if \quad 2^{p-2} = \sum^{2^{p-2}}_{j=1} \Biggr\{ 
		\begin{array}{l}
			if \ R^2_{Y \sim IV_x + \{u_j\}} > R^2_{Y \sim IV_z + \{u_j\}} \ then \ 1 \\
			else \ 0 
		\end{array}
		\label{eq:cptdom}
	\end{equation}
	
	Where $u_j$ is a distinct subset of the other $p - 2$ IVs.
	As in Table \ref{tab:exdom}, the braces surrounding $u_j$ indicate that it is a subset of non-focal IVs.
	The $D$ in this case is a designation indicating complete dominance of $IV_x$ over $IV_z$.
	Ultimately, if $IV_x$ completely dominates $IV_z$ as is outlined in Equation \ref{eq:cptdom}, $IV_x$ is clearly and unconditionally better than $IV_z$ in terms of explaining variance in $Y$ given the LRM from which all sub-models were derived.	
	
	Because complete dominance is a difficult criterion to achieve in comparing IV pairs, alternative and more compensatory, dominance designations have been proposed to provide more ways to compare the predictive usefulness of IVs against one another.
	The criteria used in the alternative dominance designations are discussed in the sections below and involve averaging the $R^2$ increment values associated with each IV and determining importance by comparing those average values.
	
	\subsection{Conditional Dominance}
	
	A less stringent dominance designation between IV pairs than complete dominance is called conditional dominance.
	Conditional dominance relaxes the stringency of the comparisons across pairs of IVs by changing the focus from comparing $R^2$ values of individual sub-models across all equivalent non-focal IV subsets to averages of increments to the $R^2$ made by the focal IV across specific sub-models.	
	By comparing averages of $R^2$ increments, as opposed to individual sub-model $R^2$ values, conditional dominance allows some sub-models with higher $R^2$ increment values to compensate for sub-models with lower $R^2$ increment values.
	Conditional dominance comparisons are then more likely to result a focal IV dominating another.
	
	The averages computed for conditional dominance group the sub-models by the number of included IVs.
	Conditional dominance averages are grouped by the number of IVs in the sub-model as, in general, including more IVs in a sub-model reduces the incremental contribution any one IV can make to the $R^2$.
	Hence, conditional dominance averages avoid dependence on inclusion order by computing average increment values for all possible inclusion orderings of each IV.
	
	The average increments to the $R^2$ used in determining conditional dominance are known as conditional dominance statistics.
	Because each IV has a conditional dominance statistic for each number of IVs in the sub-model, with $p$ IVs, each IV will have $p$ conditional dominance statistics to compare to another IV.
	Extending on Table \ref{tab:exdom}, determining conditional dominance between $IV_x$ and $IV_z$ would involve all four different conditional dominance statistics, the computation of which are outlined below in Table \ref{tab:excdl}.
	
	\begin{table}[h!]
		\centering
		\caption{\centering Example Conditional Dominance}
		\begin{tabular}{ l | l l }
			Comparing at & Average with $IV_x$ & Average with $IV_z$ \\
			\hline
			One IV & $\Delta R^2_{Y \sim IV_x + \{\emptyset\}}$ & $\Delta R^2_{Y \sim IV_z + \{\emptyset\}}$ \\
			\hline
			& $(\Delta R^2_{Y \sim IV_x + \{IV_w\}} + $ & $(\Delta R^2_{Y \sim IV_z + \{IV_w\}} + $ \\
			Two IVs & $\Delta R^2_{Y \sim IV_x + \{IV_v\}} + $ & $\Delta R^2_{Y \sim IV_z + \{IV_v\}} + $ \\
			& $\Delta R^2_{Y \sim IV_x + \{IV_z\}})\frac{1}{3}$ & $\Delta R^2_{Y \sim IV_z + \{IV_x\}})\frac{1}{3} $ \\
			\hline
			& $(\Delta R^2_{Y \sim IV_x + \{IV_w + IV_v\}} + $ & $(\Delta R^2_{Y \sim IV_z + \{IV_w + IV_v\}} + $ \\
			Three IVs & $\Delta R^2_{Y \sim IV_x + \{IV_w + IV_z\}} + $ & $\Delta R^2_{Y \sim IV_z + \{IV_w + IV_x\}} + $ \\
			& $\Delta R^2_{Y \sim IV_x - \{IV_v + IV_z\}})\frac{1}{3}$ & $\Delta R^2_{Y \sim IV_z + \{IV_v + IV_x\}})\frac{1}{3}$ \\
			\hline
			Four IVs & $\Delta R^2_{Y \sim IV_x + \{IV_w + IV_v + IV_z\}}$ & $\Delta R^2_{Y \sim IV_z + \{IV_w + IV_v + IV_x\}}$ \\
			\hline
		\end{tabular}
		\label{tab:excdl}
	\end{table}
	
	The $\Delta$ used in Table \ref{tab:excdl} indicates that the $R^2$ value is an increment made by the focal IV beyond the subset of non-focal IVs in braces.
	Note that the conditional dominance statistics use $R^2$ increments from subsets that include all other non-focal IVs.
	Hence, conditional dominance comparisons between two IVs will include increments from the IV against which they are being compared in their average value.
	This is a noteworthy difference from complete dominance designations that do not use sub-model $R^2$ values that include the IV against which the focal IV is being compared.
	
	The process of computing conditional dominance statistics for $IV_x$ at $i$ IVs in the sub-model can be formalized as in Equation \ref{eq:cdlst} below.
	
	\begin{equation}
		C^{i}_{IV_x} = \frac{\sum^{k_i}_{g=1} \Delta R^2_{IV_x + \{o_g\}}}{k_g}
		\label{eq:cdlst}
	\end{equation}
	
	Where $k_i$ is the number of combinations of size $i$ given $p$ IVs and $o_g$ is a distinct subset of the $p-1$ IVs of size $i - 1$ that are included in the sub-model.	
	The process for determining conditional dominance between two IVs, $IV_x$ and $IV_z$, is defined in Equation \ref{eq:cdldom}.
	
	\begin{equation}
		IV_x \ D_c \ IV_z \quad if \quad p = \sum^p_{i=1} \Biggl\{ 
		\begin{array}{l}
			if \ C^{i}_{IV_x} > C^{i}_{IV_z} \ then \ 1 \\ 
			else \ 0 
		\end{array}
		\label{eq:cdldom}
	\end{equation}
	
	The $D_c$ is a designation indicating conditional dominance of the $IV_x$ over $IV_z$.	
	When $IV_x$ does not completely but does conditionally dominate $IV_z$, $IV_x$ is generally better than $IV_z$ for explaining variance in $Y$ given the underlying LRM irrespective of inclusion order in the model.
	Conditional dominance thus suggests that $IV_x$'s explanatory value is not generally sensitive to the order in which it enters the model compared to $IV_z$ and that it is more important conditional on the number of IVs in the sub-model.
	
	Conditional dominance between an IV pair is much less stringent than complete dominance but can still be a difficult designation to meet in models with a great deal of between-IV overlap.
	As a result, a third dominance designation was developed that involves yet another averaging step and is described in the next section.
	
	\subsection{General Dominance}
	
	The least stringent dominance designation between IV pairs is called general dominance.
	General dominance further relaxes the stringency of the comparisons between IV pairs by changing the focus from comparing average increments grouped by the number of IVs in a sub-model to the arithmetic average of these averages.
	General dominance is then the average of the conditional dominance statistics for each IV.
	By averaging over conditional dominance statistics, general dominance allows higher contributions at specific numbers of IVs in the sub-model to compensate for lower contributions at other numbers of IVs in the sub-model. 
	The values generated by general dominance will, in almost all cases, produce a dominance designation between the pair of IVs.
	
	The averaged conditional dominance statistics computed for determining general dominance are known as general dominance statistics. 
	Table \ref{tab:exgen} shows the general dominance statistic computation for $IV_x$ and $IV_z$.
	This computation incorporates all the values in Table \ref{tab:excdl} but summed into a single statistic.
	
		\begin{table}[h!]
		\centering
		\caption{\centering Example General Dominance}
		\begin{tabular}{ l l }
			Average with $IV_x$ & Average with $IV_z$ \\
			\hline
			$\Delta R^2_{Y \sim IV_x + \{\emptyset\}}\frac{1}{4} + $ & $\Delta R^2_{Y \sim IV_z + \{\emptyset\}}\frac{1}{4} +$ \\
			$(\Delta R^2_{Y \sim IV_x + \{IV_w\}} + $ & $(\Delta R^2_{Y \sim IV_z + \{IV_w\}} + $ \\
			$\Delta R^2_{Y \sim IV_x + \{IV_v\}} + $ & $\Delta R^2_{Y \sim IV_z + \{IV_v\}} + $ \\
			$\Delta R^2_{Y \sim IV_x + \{IV_z\}})\frac{1}{12} + $ & $\Delta R^2_{Y \sim IV_z + \{IV_x\}})\frac{1}{12} + $ \\
			$(\Delta R^2_{Y \sim IV_x + \{IV_w + IV_v\}} + $ & $(\Delta R^2_{Y \sim IV_z + \{IV_w + IV_v\}} + $ \\
			$\Delta R^2_{Y \sim IV_x + \{IV_w + IV_z\}} + $ & $\Delta R^2_{Y \sim IV_z + \{IV_w + IV_x\}} + $ \\
			$\Delta R^2_{Y \sim IV_x - \{IV_v + IV_z\}})\frac{1}{12} + $ & $\Delta R^2_{Y \sim IV_z + \{IV_v + IV_x\}})\frac{1}{12} +$ \\
			$\Delta R^2_{Y \sim IV_x + \{IV_w + IV_v + IV_z\}}\frac{1}{4}$ & $\Delta R^2_{Y \sim IV_z + \{IV_w + IV_v + IV_x\}}\frac{1}{4}$ \\
			\hline
		\end{tabular}
		\label{tab:exgen}
	\end{table}

	As is implied by the computations in Table \ref{tab:exgen}, general dominance statistics are a weighted average of the individual increments to the $R^2$s and is defined for $IV_x$ in Equation \ref{eq:genst}.
	
	\begin{equation}
		C_{IV_x} = \frac{\sum^{p}_{i=1} C^i_{IV_x}}{p}
		\label{eq:genst}
	\end{equation}
	
	Using the general dominance statistics computed in Equation \ref{eq:genst}, determining whether $IV_x$ generally dominates $IV_z$ is defined in Equation \ref{eq:gendom}.
	
	\begin{equation}
		IV_x \ D_g \ IV_z \quad if \quad C_{IV_x} > C_{IV_z}
		\label{eq:gendom}
	\end{equation}
	
	The $D_g$ is a designation indicating general dominance of $IV_x$ over $IV_z$.	
	When $IV_x$ does not completely or conditionally but does generally dominate $IV_z$, $IV_x$ is generally better than $IV_z$ for explaining variance in $Y$ given the underlying LRM but is sensitive to inclusion order in the model.
	General dominance thus suggests that $IV_x$'s predictive usefulness is, on average, better than $IV_z$ and that it is more important when discounting the effects of IV inclusion order.
	
	Note that the  general dominance statistic values, when summed across the $p$ IVs, equals the sub-model $R^2$ when all $p$ predictors are included.
	This is a useful feature of these statistics that, as has been discussed in other reviews \parencite{gromping2007estimators,johnson2004history}, ties this method to earlier work on IV importance focusing on the decomposition of the $R^2$ statistic.

	In the sections above, I have provided a brief discussion of DA's development and reviewed how DA statistics are computed and designations are determined.
	In the section below, I transition from a broad outline of DA to a more targeted discussion on application of DA to CRMs.
	The focus of the section discussion of CRM-based DA focuses on considering which fit metric should be used when applying DA to CRMs.
	
\section{Applying Dominance Analysis to Count Regression Models}

	A complication of applying DA to CRMs is that most of the literature on DA has focused on its application to LRM with the variance explained $R^2$.
	Given the semi-continuous nature of count DVs and that the output from CRMs is typically in the form of a predicted count/mean value, the $R^2$ could be applied to CRM-based DA.
	
	Although the variance explained $R^2$ could be applied, there are good conceptual reasons to choose another fit metric. 
	In the section below, I provide a detailed rationale for the choice of a different metric, the deviance $R^2$ (i.e., $R^2_{DEV}$), that better reflects how CRMs fit to data. 
	
	\subsection{Count Regression Fit Metric: Deviance $R^2$}
	
	CRMs such as PR and NBR are not only log-linear models but follow the discrete Poisson and negative Binomial probability distributions.
	That both of these CRMs follow a distribution that is not the Normal distribution is important to consider when evaluating model fit.
	This is because statistical models are fit using information about the data as applied to a probability distribution to find their most likely parameter values.
	Thus, choosing a fit metric that matches the probability distribution's underlying fitting criterion will best reflect how the model fits to data.
	
	In considering how fit metrics reflect underlying fitting criteria, I find it instructive to first consider the LRM.
	LRM is based on a Normal or Gaussian probability distribution that has been shown to have least-squares as its fitting criterion which seeks to minimize $SS_{residual} = \sum (Y - \hat{Y})^2$ or the residual sums of squares between the predicted values from the LRM and the observed DV. The computation used to obtain the $SS_{residual}$ is also known as the deviance ($DEV$) for the Normal distribution as it describes how the model's predictions deviate from observed values \parencite{mccullagh2019generalized}.
	The $SS_{residual}$ can then be cast as $DEV_{model}$ or a model deviance for the LRM.
	
	Deviance computations apply to CRMs but can differ substantially from the LRM's least squares criterion.
	For example, the deviance for PR and a special case of the NBR\footnote{
		This special case is the NBR estimated using a quasi-likelihood method. 
		Maximum likelihood methods require a more complex form given the estimation of the $\alpha$ parameter.} 
	is $\sum Y\ln \frac{Y}{\hat{Y}} - (Y - \hat{Y})$. 
	Note that this PR-focused deviance value differs notably from the Normal distribution deviance in that it tends to penalize underprediction more than overprediction.
	The extra penalties assigned to underprediction are consistent with the truncated, semi-continuous nature of count DVs in that they cannot go below 0 and, thus, tend to be penalized more heavily toward the conceptual lower bound of the distribution.
	By contrast, Normal distribution deviance has no such constraint and penalizes discrepancies from observed values equally in either direction.
	
	The difference between the deviance computations across LRM and CRMs in terms of their implications for model fit was first discussed by Cameron and Windmeijer \parencite*{cameron1996r} who devise the $R^2_{DEV}$ or deviance $R^2$ outlined in Equation \ref{eq:r2dev} below.
	
	\begin{equation}
		R^{2}_{DEV} = 1 - \frac{DEV_{model}}{DEV_{null}}
		\label{eq:r2dev}
	\end{equation}
	
	Where $DEV_{null}$ is a deviance for an intercept- or mean-only model.
	
	As Cameron and Windmeijer note, the explained variance $R^2$ used in LRM is, in fact, a $R^2_{DEV}$ for the LRM as it can be cast as $1 - \frac{SS_{residual}}{SS_{total}}$ where $SS_{total} = \sum (Y - \bar{Y})^2$ which is equivalent to $DEV_{null}$ for the LRM.
	Consequently, a researcher applying the explained variance $R^2$ to a CRM is applying a fit metric that is meant for LRM's fitting criterion to evaluating model to data fit for a CRM.
	Ultimately, I recommend using the $R^{2}_{DEV}$ with deviance computations for $DEV_{model}$ and $DEV_{null}$ that are based on each CRM's fitting criterion as they are a much better conceptual fit for CRM-based DA.
	
	In this section I have provided a rationale for the choice of a specific fit metric to use when applying DA to CRMs.
	In the sections to follow, I transition to an example application of the methodology to CRMs.
	This discussion briefly outlines the data generated for this purpose, describes the models estimated from the data, and also describes how DA statistics and designations were determined.
	
	\subsection{Count Regression Model-based Dominance Analysis: An Analytic Example}
	
	The goal of this section is to provide an example analysis using the recommended $R^2_{DEV}$ CRM-based DA methodology.
	This  example is intended to be useful as a guide for researchers and analysts interested in applying this method to CRMs.
	In the section below, I begin by describing how I generated data for the example based on a PR model\footnote{
		An example using a NBR is available in the online supplement.}.
	The methods used to generate these data are not directly relevant to the goals of this manuscript and, as such, have been put into an online supplement.
	Please note that the online supplement outlines the code to generate the data and development perspective behind the generation of these data in great detail.
	The section below is focused primarily on describing the conceptual nature of the data so that the reader can follow along prior to transitioning to analysis.
	
		\subsubsection{Data Generation}
	
	The study described below intends to evaluate the effect of four different tailoring shop characteristics on the output of each shop.
	The data for this analysis describe a sample of 6,780 tailoring shops over a two-week period of time.
	The count DV output of each of these shops is the number of sport jackets (called $SJ$ below) finished by the shop in the two-week time period.
	The sport jackets produced by these shops are garments developed from a template and are of standard sizes and measurements.
	As such, the jackets are expected to show little extra variation and were expected to be Poisson distributed.
	
	There were four measured tailoring shop characteristics used to predict sport jacket output. 
	The first characteristic was an expert's assessment of the shop's equipment reliability (called $ER$ in results below).
	Equipment reliability reflects the ease of use of the shop's equipment for the staff and the extent to which it is likely to fail to operate when needed. 
	The second characteristic was the sufficiency of tailoring assistant staffing levels (called $AS$ in results below).
	Understaffed tailoring shops are likely to suffer from reduced productivity given a shortage of labor.
	A third characteristic is the managing tailor's level of skill (called $SL$ in results below).
	More skilled managing tailors are more likely than less skilled managers to have designed processes that facilitate jacket completion.
	Finally, the last characteristic is the managing tailor's work experience (called $WE$ in results below).
	Similar to skill-level, more experienced managing tailors are likely to have designed processes that improve garment production.
	
	The means, standard deviations, and correlations between all four IVs and two DVs are reported below in Table \ref{tab:desc}. 
	
	\begin{table}[h!]
		\centering
		\caption{\centering Descriptive Statistics} 
		\begin{tabular}{lrr|rrrrr}
			\hline %\toprule
			&  & Standard & \multicolumn{5}{c}{Correlations} \\ 
			Variable & Mean & Deviation & $ER$ & $AS$ & $SL$ & $WE$ & $SJ$ \\ 
			\hline %\midrule
			$ER$ & $-0.0355$ & $1.1853$ & $1.0000$ & $0.4168$ & $0.1446$ & $0.2180$ & $0.4175$ \\ 
			$AS$ & $-0.0261$ & $1.4494$ & $0.4168$ & $1.0000$ & $0.1958$ & $0.2850$ & $0.3592$ \\ 
			$SL$ & $-0.0056$ & $1.5480$ & $0.1446$ & $0.1958$ & $1.0000$ & $0.3295$ & $0.2913$ \\ 
			$WE$ & $0.0144$ & $1.9211$ & $0.2180$ & $0.2850$ & $0.3295$ & $1.0000$ & $0.3726$ \\ 
			$SJ$ & $0.9940$ & $1.0082$ & $0.4175$ & $0.3592$ & $0.2913$ & $0.3726$ & $1.0000$ \\ 
			\hline %\bottomrule
		\end{tabular}
		\label{tab:desc}
	\end{table}

	One point of note about the 6,780 tailoring shops revealed in Table \ref{tab:desc} is that, on average, each of them produced a single jacket in the two-week period under study.
	In addition, the variance of sport jacket production was consistent with its expected underlying distribution.
	Specifically, sport jacket production had a variance of 1 which closely matches the mean as is assumed of the Poisson distribution. 
	
	Given that the sport jacket production DV fits the requirements of a Poisson distribution, in the next section I estimate a PR predicting it using the four shop characteristic IVs.

		\subsubsection{Regression Results}
		
	The PR results using the four shop characteristic IVs to predict sport jacket counts are reported in Table \ref{tab:poisreg}. 
	Table \ref{tab:poisreg} includes coefficients ($\beta$), standard errors ($\sigma_{\beta}$), the the 95\% confidence interval, and the exponentiated coefficient or incidence rate ratio/IRR ($e^{\beta}$).
	
	\begin{table}[h!]
		\centering
		\caption{\centering Poisson Regression Predicting Sport Jackets Produced} 
		\begin{tabular}{l|rrrrr}
			\hline %\toprule
			\multicolumn{1}{l}{} &  &  & \multicolumn{2}{c}{95\% Confidence Interval} &   \\ 
			\multicolumn{1}{l}{} & $\beta$ & $\sigma_{\beta}$ & Low & High & $e^{\beta}$ \\ 
			\hline %\midrule
			$ER$ & $0.2431$ & $0.0114$ & $0.2208$ & $0.2655$ & $1.2753$ \\  
			$AS$ & $0.1081$ & $0.0095$ & $0.0896$ & $0.1267$ & $1.1142$ \\ 
			$SL$ & $0.0999$ & $0.0083$ & $0.0835$ & $0.1162$ & $1.1050$ \\
			$WE$ & $0.1158$ & $0.0069$ & $0.1024$ & $0.1293$ & $1.1228$ \\ 
			$Intercept$ & $-0.1507$ & $0.0138$ & $-0.1780$ & $-0.1237$ & $0.8601$ \\
			\hline %\bottomrule
		\end{tabular}
		\label{tab:poisreg}
	\end{table}

	Table \ref{tab:poisreg} shows that each of the IVs has a positive effect on the number of sport jackets produced and appear to be statistically significant (at the $p < .05$ level) as is implied by the confidence intervals.
	
	In terms of effect size magnitude, equipment reliability had the largest effect on sport jacket counts. 
	The IRR value shows that each one point increase in equipment reliability led to a 27.5\% increase in the number of sport jackets finished.
	Tailor work experience obtained the second-largest effect on sport jacket counts with its IRR value showing that each one point increase in staffing levels led to a 12.3\% increase in the number of sport jackets finished.
	Assistant staffing and skill level obtained the smallest effect sizes as reflected by their IRRs.
	Assistant staffing resulted in a 11.4\% increase and work experience a 10.5\% increase in the number of sport jackets produced in two weeks. 
	
	The IRR value for the model intercept reports on the average number of sport jackets when all IVs are 0; for these results, the number of jackets produced with all four IVs at its mean value. 
	The .8601 value obtained is similar to the overall mean of near 1 reported in Table \ref{tab:desc}.
	This .8601 value can also used as a baseline prediction for the PR.
	For instance, the expected number of sport jackets with equipment reliability at 1 and all other IVs at 0 is $.8601*1.2753 = 1.0969$ or just above 1 jacket.
	Contextualizing model predictions by reporting out specific predicted values is useful for non-linear models such as PR as they more clearly depict the multiplicative effects produced by CRMs.
	Hence, reporting on and visualizing predicted marginal means adds value to the model interpretation process \parencite[see][for a similar perspective]{ronkko2022eight}.
	Although I do not report marginal means plots in the body of this manuscript for brevity, such plots are reported in the online supplement for interested readers.
	
	The PR modeling result reported in Table \ref{tab:poisreg} shows that all four IVs have predictive effects on sport jacket production and, in addition, show different effect size magnitudes that indicate likely differences in the importance of each IV for explaining sport jacket production.
	
	In the section below, I transition to the focal analysis of this work where I determine the importance of each IV for predicing sport jacket production using DA.
	In this way, the section below provides an empirical example that applies the designation and computational formulas in Equations \ref{eq:cptdom}, \ref{eq:cdlst}, \ref{eq:cdldom}, \ref{eq:genst}, and \ref{eq:gendom} to the PR model in Table \ref{tab:poisreg}.
	
		\subsubsection{Dominance Analysis Results}
	
	DA designations and statistics are built from the collection of model fit statistics representing all sub-models.
	The four tailoring shop IVs used in this manuscript result in $2^4 = 16$ sub-models.
	The results from all model sub-sets are reported below in Table \ref{tab:r2sub} omitting the sub-model with no predictors as it will produce a 0 value.
	
	\begin{table}[h!]
		\centering
		\caption{\centering $R^2_{DEV}$ by Sub-model}
		\begin{tabular}{l|r}
			\hline %\toprule
			$SJ \sim ER$ & $0.1524$ \\ 
			$SJ \sim AS$ & $0.1131$ \\ 
			$SJ \sim SL$ & $0.0744$ \\ 
			$SJ \sim WE$ & $0.1219$ \\ 
			$SJ \sim ER + AS$ & $0.1887$ \\ 
			$SJ \sim ER + SL$ & $0.2006$ \\ 
			$SJ \sim ER + WE$ & $0.2248$ \\ 
			$SJ \sim AS + SL$ & $0.1584$ \\ 
			$SJ \sim AS + WE$ & $0.1844$ \\ 
			$SJ \sim SL + WE$ & $0.1502$ \\ 
			$SJ \sim ER + AS + SL$ & $0.2266$\\ 
			$SJ \sim ER + AS + WE$ & $0.2442$ \\ 
			$SJ \sim ER + SL + WE$ & $0.2459$ \\ 
			$SJ \sim AS + SL + WE$ & $0.2050$ \\ 
			$SJ \sim ER + AS + SL + WE$ & $0.2624$ \\ 
			\hline %\bottomrule
		\end{tabular}
		\label{tab:r2sub}
	\end{table} 

	A few points can be gleaned from the results in Table \ref{tab:r2sub}. 
	For example, Table \ref{tab:r2sub} shows that equipment reliability appears to be associated with larger $R^2_{DEV}$ values and is likely to be an important variable consistent with its coefficient size. 
	The $R^2_{DEV}$ values associated with the remaining variables is harder to discern from the table but do not as clearly follow the coefficient sizes reported in Table \ref{tab:poisreg}.
	As such, it is useful to compare these values using the dominance analysis designations.
	
	The first dominance designation to evaluate using the results in Table \ref{tab:r2sub} is whether IVs show evidence of completely dominating one another.
	Equipment reliability was noted as having larger $R^2_{DEV}$ values than other variables above and, when using Equation \ref{eq:cptdom} to evaluate equipment reliability relative to the other three IVs, is shown to completely dominate all three.
	Thus, equipment reliability is the undisputed top predictor of sport jacket production irrespective of IV inclusion ordering in the model.	
	
	The complete dominance relationships between the remaining variables is far less clearly defined. 
	For instance, work experience completely dominates skill level but does not completely dominate assistant staffing.
	Moreover, assistant staffing and skill level have no complete dominance relationship.
	This makes clearly ranking the final three variables more nuanced as work experience is a better predictor than skill level irrespective of inclusion order, but no such clear statement can be made of the rest of the comparisons.
	Thus, work experience is likely the second best predictor but it will require one of the expanded dominance designations to confirm this is the case.
	
	In order to rank the remaining variables, the conditional dominance statistics for all the tailoring shop IVs were computed using Equation \ref{eq:cdlst}.
	The results of the conditional dominance statistic computations are depicted graphically in Figure \ref{fg:cdl} below.
	For this Figure, the y-axis is on a log scale to improve legibility nearer subsets sizes of 4.
	
	\begin{figure}[h!]
		\centering
		\caption{\centering Conditional Dominance Statistics}
		\includegraphics{condit_gph}
		\label{fg:cdl}
	\end{figure}

	The graphic format is useful for the reporting of conditional dominance statistics with only a few IVs as the relative orientation of each of the lines reflects the nature of the conditional dominance designation implemented in Equation \ref{eq:cdldom}.
	Specifically, if an IVs conditional dominance trendline is always above, and thus never crosses over, another IV's conditional dominance trendline, the IV that is above conditionally dominates the one below.
	Figure \ref{fg:cdl} confirms the complete dominance results in that equipment reliability's line is above the lines for the other three IVs indicating that it dominates each of them.
	Similarly, work experience's line is above skill level's line consistent with the complete dominance results.
	In addition, work experience's line is above assistant staffing's line indicating that it conditionally dominates assistant staffing.
	Although work experience does not explain more than assistant staffing in all comparable models (see Table \ref{tab:r2sub}; specifically, $SJ \sim AS + SL$ versus $SJ \sim SL + WE$'s values), when considering the average increment by number of IVs included, work experience produces bigger increments to the $R^2_{DEV}$ than does assistant staffing levels. 
	As such, work experience's dominance of assistant staffing is model dependent, but not dependent on IV inclusion order.
	
	The conditional dominance relationships for the last two IVs does not offer a different designation than did the complete dominance results.
	Assistant staffing fails to conditionally dominate skill level given skill level's conditional dominance statistic at subset size 4.
	These conditional dominance results further reinforce the idea that attempting to rank these IVs is not straightforward and their contributions to prediction depend on the order of their inclusion in the model. 
	
	Given that no complete or conditional dominance designations were possible for comparing assistant staffing with skill level, I proceed to evaluating the general dominance designations between these variables. 
	The general dominance statistics for each tailoring shop IV was computed using Equation \ref{eq:genst} and are reported in Table \ref{tab:gen}.
	
	\begin{table}[h!]
		\centering
		\caption{\centering General Dominance Statistics}
		\begin{tabular}{l|r}
			\hline %\toprule
			$ER$ & $0.0965$ \\ 
			$AS$ & $0.0560$ \\ 
			$SL$ & $0.0399$ \\ 
			$WE$ & $0.0700$ \\ 
			\hline %\bottomrule
		\end{tabular}
		\label{tab:gen}
	\end{table}

	Evaluating the general dominance designations implied by the general dominance statistics in Table \ref{tab:gen} using Equation \ref{eq:gendom} again shows that equipment reliability dominates each other variable and that work experience dominates skill level and assistant staffing. 
	The general dominance statistics add to the prior dominance designations by determining that assitant staffing generally dominates skill level.
	The general dominance designations then add to the results above in that they allow for a clear rank ordering of the tailoring shop IVs in predicting sport jackets with equipment reliability being the most important followed by work experience, then assistant staffing, and ending with skill level.
	
	In conclusion, the DA results have built on reports of the model in Table \ref{tab:poisreg} by adding additional information about how each of the tailoring shop IVs explains variation or information in the sport jacket production variable. 
	The DA results support the inference about the large IRR value obtained by equipment reliability, confirming that this variable, regardless of the order in which it might be included in the model, is most important. 
	In addition, equipment reliability is associated with nearly one-third (i.e., $\frac{.0965}{.2624} \approx \frac{1}{3}$ of the explained information in sport jackets alone).
	The DA results also provide useful contextualization of the other three IV's IRR values from Table \ref{tab:poisreg}.
	Specifically, the IRR values for work experience, assistant staffing levels, and skill level were similar, each within .01 of one another. 
	It would then seem like each IV might have a similar importance comparison with each other IV.
	The dominance designations obtained showed this is not the case as work experience completely dominated only skill level and conditionally dominated assistant staffing levels. 
	Moreover, assistant staffing levels generally dominated skill level.
	The DA results then showed a great deal of variability in terms of strength of dominance designations even within this rather narrow window of IRR values.
	
\section{Discussion}

	In this manuscript I have recommended a methodology for determining the relative importance of IVs in CRMs.
	Specifically, I recommend the DA methodology as an approach that is comprehensive in the information it provides about IV's prediction and, when using an appropriate fit metric such as the $R^2_{DEV}$, can apply to CRMs and provide information analogous to the explained variance $R^2$ using the LRM.
	
	In addition, I walk the reader through an example data analysis applying PR to simulated data. 
	In walking the reader through this example, I use the recommended DA with $R^2_{DEV}$ fit statistic approach to evaluate the relative importance of the four IVs in the simulated data.
	This walk through of the DA focuses on interpreting IV importance with a focus on how meeting different levels of DA designation stringency offers different evidence for the importance of the IVs over one another.
	
	In combination, this manuscript picks up where Blevins et al. \parencite*{blevins2015count} had left off by recommending the use of a specific postestimation method, DA, for better understanding model prediction as well as expanding on specific issues that affect CRMs.
	It remains important to continue to consult their work when choosing to implement a CRM as their decision flowchart can help the researcher to choose the most appropriate CRM given the nature of the data.
	I recommend that you follow the estimation of the CRM with a DA to more fully understand and contextualize the predictions made by each IV.
	
	I have touched on many of the key aspects necessary for extending DA to CRM in this manuscript but acknowledge that I have not been able to discuss all relevant issues for determining IV importance in CRMs.
	Below I discuss some noteworthy limitations and additional extensions of this work before closing.
	
	\subsection{Limitations and Future Directions}
	
	In this work, I use only a series of PR models with simulated data to provide empirical examples.
	The use of PR with simulated data was an intentional choice to avoid the need to work through many of the decision points outlined by Blevins et al. \parencite*{blevins2015count} related to the selection of the appropriate CRM.
	In addition, the use of simulated data allowed for designing an underlying dataset that had specific properties.
	The results of the NBR-based DA are very similar to those of the PR-based DA given the same underlying data generating model.
	As such, I did not see adding it to the main manuscript as worth the space it would take to describe and have left it in the supplement for any interested reader.
	I will acknowledge before moving on that the use of the simulated data as I have done in this manuscript adds additional complexity to following along with the methodology in the online supplement.
	That said, all the procedures used to simulate the various count DVs are fully replicable, well-documented, and available as a markdown that can be used by interested readers with a working knowledge of R \parencite{R}.
	
	Prior work on DA has suggested the application of bootstrapping to estimate standard errors for general dominance statistics and reproduce-ability values for other dominance designations \parencite{azen2009using,braun2019accuracy}. 
	Bootstrapping the CRM-based dominance statistics and designations is possible for CRM-based DA in the same way as was outlined for logistic regression by Azen and Traxel \parencite*{azen2009using} but is not examined in the present work.
	A substantial complication with the application of standard errors to DA statistics is in providing clear, compelling rationale as to the differences in roles that null hypothesis testing plays in testing coefficients as compared to DA statistics.
	At current, the literature does not offer useful guidelines about how the roles of each type of hypothesis test might affect the interpretation of the model and the research questions it seeks to answer.
	
	In addition, zero-inflation is a commonly observed condition in count DVs that has been discussed extensively in prior work \parencite[e.g.,][]{blevins2015count}. 
	Cameron and Windmeijer \parencite*{cameron1996r} discuss the application of the $R^2_{DEV}$ to zero-inflated CRMs and, thus, a DA methodology based on the same general approach as discussed above could be applied to zero-inflated CRMs.
	One additional complication that arises with considering how to determine importance with zero-inflated models is that zero-inflated CRMs model two processes in the data. 
	The first process is the standard count generating process whereby IVs increase or decrease counts of the DV.
	The second is an "opt out" process whereby IVs increase or decrease the likelihood of the count being 0.
	An additional complication introduced by the two processes modeled by zero-inflated CRMs is that it is possible to allow specific IVs to predict the count generating process, the opting out process, or both.
	In such circumstances the researcher should consider whether an alternative approach that emphasizes parameter estimates as opposed to IVs is better suited to the importance determination with DA \parencite{luchman2020relative}.
	
	\subsection{Conclusion}
	
	DA is a useful post-estimation methodology for determining the importance of IVs in statistical models such as CRMs.
	This manuscript has provided a recommended methodology for extending DA to CRMs and offered extensive examples focusing on the interpretation of DA statistics and designations with simulated data.
	In combination, the conceptual discussion of DA and CRMs when paired with the empirical examples in this paper, will provide organizational and other behavioral scientists with the tools necessary for better understanding the results of CRMs they estimate and to more completely answer research questions to which CRMs are applied.

\printbibliography
	
\end{document}

input{CountDominance.bbl}