---
title: Count Regression Model Dominance Analysis
subtitle: Documentation
#author: Joseph Luchman
author: Anonymized for review
output: html_notebook
editor_options: 
  markdown: 
    wrap: 72
---

This notebook provides documentation for the generation of the data used in the manuscript **Relative Importance Analysis with Count Regression Models**.

The documentation and discussion of approach in this document extends on that provided in the main manuscript as the discussion here focuses more closely on implementation details. These implementation details are are not essential for the reader to understand the manuscript but are essential for understanding the analytic context and for reproducibility.

The code block below initiates the analysis by setting the R environment.

A component of this environment is the random seed to be able to fully reproduce the data. 

Details on the random seed as well as the details of the R environment are available at the end of this notebook.

```{r set-up, results='hide'}
library(gt)
library(knitr)
library(kableExtra)
library(MASS)
library(pscl)
library(tidyverse)
library(magrittr)
library(domir)
library(parameters)
library(datawizard)
library(MCMCpack)

set.seed(84490856)
```

# Data Generation

The manuscript describes four IVs including:

  a. equipment reliability or _ER_
  b. assistant staffing levels or _AS_
  c. tailor skill-level or _SL_
  d. tailor work experience or _WE_
  
This section provides details related to the population-level parameters used to generate the data used for analysis.

## Generate IV Data

The generation of the four IVs begins with setting up a population-level covariance matrix describing the variances of and interrelationships between the IVs.

The four IVs were designed such that they would have different variances. The variances chosen were four equally spaced values between standard deviation values of 1 and 2. The first IV, _ER_, was then designed to have a $\sigma_{ER} = 1.00$ and $\sigma^2_{ER} = 1.00$.The second IV, _AS_, was designed to have $\sigma_{AS} = 1.33$ and of $\sigma^2_{AS} = 1.78$.  _SL_ was designed to have $\sigma_{SL} = 1.67$ and $\sigma^2_{SL} = 2.78$.  Finally, _WE_ was designed to have $\sigma_{WE} = 2.00$ and $\sigma^2_{WE} = 4.00$.

The design of the interrelationships between the IVs was implemented as to give the IVs non-zero overlaps between one another. This was done as DA is most useful, as a methodology for inferring importance, when the IVs overlap. Although the IVs were designed to overlap, I did not want the extent of the overlap between the IVs to be such that some IVs were more redundant with other IVs than other IVs. All six correlations between the four IVs were thus designed to take on one of three values .250, .125, and .063. These three values were "balanced" across IVs such that the total redundancy for any one IV was identical to the others. 

The six different correlations specified were: $r_{ER,AS} = .250$, $r_{ER,SL} = .125$, $r_{ER,WE} = .063$, $r_{AS,SL} = .063$, $r_{AS,WE} = .125$, and $r_{SL,WE} = .250$.

The manuscript notes that a goal for the generation of the data for analytic use in this exercise is to obtain data that are 'realistic.' The balanced correlations that are determined at the population-level fail to 'feel real.' 

In an effort to add more realism to the dataset, the population covariance matrix is filtered through an inverse Wishart distribution using a single draw and large value (i.e., 100) for the degree of freedom parameter.

Sampling from the inverse Wishart distribution will produce a set of correlation values that are based on the balanced approach but appear more 'as though' they were generated by a real data generating process. The large value for the degrees of freedom has the effect of reducing the variances of the sampled matrix but also stabilizes the correlations of the values sampled to be closer to the population values. The variances of all the variables, once generated in the data, are multiplied by 100 to re-adjust them back to near their original values.

### Population Values

This section sets the population-level covariance matrix.

```{r gen-iv-mat}
namelist <- 
  c("ER", "AS", "SL", "WE")

Covariance_Matrix <- 
  c(1, .5^(2:4)*sqrt(1*c((4/3)^2, (5/3)^2, 4))*sqrt(1),
    .5^2*sqrt(1)*sqrt(1*(4/3)^2), (4/3)^2, .5^(4:3)*sqrt(1*(4/3)^2)*sqrt(1*c((5/3)^2, 4)),
    .5^(3:4)*sqrt(1*(5/3)^2)*sqrt(1*c(1, (4/3)^2)), (5/3)^2, .5^2*sqrt(1*(5/3)^2)*sqrt(1*4),
    .5^(4:2)*sqrt(1*4)*sqrt(1*c(1, (4/3)^2, (5/3)^2)), 4) %>%
  matrix(nrow = 4, byrow = TRUE)

Covariance_Matrix %>% 
  as.data.frame() %>%
  set_names(namelist) %>%
  set_rownames(namelist) %>%
  gt(rownames_to_stub = TRUE) %>%
  tab_header("Table S1: Population Covariance Matrix") %>%
  fmt_number(columns = 2:5, decimals = 4)

Covariance_Matrix %>% cov2cor() %>% 
  as.data.frame() %>%
  set_names(namelist) %>%  
  set_rownames(namelist) %>%
  gt(rownames_to_stub = TRUE) %>%
  tab_header("Table S2: Population Correlation Matrix")
```

Tables S1 and S2 confirm the correct/intended values are in the covariance and correlation matrices.

### Sampled Values

This section uses the set population covariance matrix as the scale parameter and a value of 100 as a degree of freedom parameter to obtain a single draw from the inverse Wishart distribution.  

The important component obtained by this sampled matrix is the correlations it produces. The covariance matrix will be updated/rescaled once the data are generated.

```{r sample-iv-mat}
Covariance_Matrix_Use <- 
  riwish(100, Covariance_Matrix)

Covariance_Matrix_Use %>% 
  as.data.frame() %>%
  set_names(namelist) %>%
  set_rownames(namelist) %>%
  gt(rownames_to_stub = TRUE) %>%
  tab_header("Table S3: Sampled Covariance Matrix") %>%
  fmt_number(columns = 2:5, decimals = 4)

Covariance_Matrix_Use %>% cov2cor() %>% 
  as.data.frame() %>%
  set_names(namelist) %>%  
  set_rownames(namelist) %>%
  gt(rownames_to_stub = TRUE) %>%
  tab_header("Table S4: Sampled Correlation Matrix") %>%
  fmt_number(columns = 2:5, decimals = 4)
```

There are a few points of note about the sampled results from Tables S3 and S4.  

As was expected, the variances for the four IVs have shrunk substantially moving from the population to the sampled matrix. Again, the change in the variance will be corrected to a values more similar to the population values once the data are generated. Note that the relative differences between the variances maintained the population-level pattern with $\sigma^2_{WE} > \sigma^2_{SL} > \sigma^2_{AS} > \sigma^2_{ER}$.

The correlations obtained by the sampled matrix also appear plausible for behavioral science data.

### Generate Observations

This section discusses the generation of the simulated multivariate Normal data using the sampled covariance matrix. The means of the variables were set at zero.

The sample size of the generated data were also determined through a random process. Specifically, the value was a draw from a random uniform distribution falling between 5,000 and 10,000 rounded to the nearest integer. The range chosen was expected to result in a sufficiently large sample size for the data analysis demonstration yet also be 'realistic.'

```{r gen-iv-data}
total_n <- 
  runif(n = 1, min = 5000, max = 10000) %>% 
  round()

Data_Frame <- 
  mvrnorm(n = total_n, 
          mu = rep(0, times = 4), 
          Sigma = Covariance_Matrix_Use) %>% 
  as.data.frame() %>%
  multiply_by(10) %>%
  set_names(namelist)

Data_Frame %>%
  summarise(
    across(.fns = mean),
    ) %>% 
  pivot_longer(everything(), names_to = "IV Name", values_to = "Mean") %>%
  left_join(
  Data_Frame %>%
  summarise(
    across(.fns = sd),
    ) %>% pivot_longer(everything(), names_to = "IV Name", 
                       values_to = "Standard Deviation")
  ) %>%
  left_join(
    Data_Frame %>% 
      cor %>% 
      as_tibble(rownames = "IV Name")
  ) %>%
  gt(rowname_col = "IV Name") %>%
  tab_header("Table S5: Sampled Data Descriptive Statistics") %>%
  fmt_number(columns = 2:7, decimals = 4) %>%
  tab_spanner(columns = c(ER, AS, SL, WE), label = "Correlations") %>%
  tab_style(
    style = cell_borders(sides = "right"),
    locations = cells_body(columns = "Standard Deviation")
  ) %>%
  tab_source_note(str_c("Sample Size of Simulated Data is ", 
                        nrow(Data_Frame) %>% format(big.mark = ","), "."))
  

```

A total of 6,870 multivariate Normally distributed observations were simulated for this data analysis.

The variances of each of the IVs, as noted above, were re-adjusted to closer to the original, population-level range.

## Generate Underlying Normally Distributed Dependent Variable

The generation of the number of stock jackets produced (SJ; Poisson distributed) and number of made-to-measure jackets produced (MJ; negative Binomial distributed) by the tailors, both DVs for the primary analyses, began with generating a single Normally distributed variable from which both were derived.

The underlying Normally distributed variable was generated as a linear combination of the four IVs.

Four population-level coefficient values were chosen for this variable were: $\beta_{ER} =.200$,  $\beta_{AS} =.173$,  $\beta_{SL} =.155$, $\beta_{WE} =.100$. These four values were chosen as they each, when squared and multiplied by the population-level variance, would produce a value of .04---not considering IV intercorrelations.

The coefficient values used for the generated underlying jackets variable (J) were sampled in a single draw from a Normal distribution with the four population values used as means. Each mean had a shared standard deviation of .05 to add variation to the coefficient values.

The error variance for J was set to be $1 - \sigma^2_{J}$ thus forcing the variance of J to be 1. The mean of J is also set to be 0.
	
### Population Values

This section sets the population coefficient values.

```{r pop-coefs}
Coefficient_Vector <- 
  c(.2, sqrt(.04/(4/3)), sqrt(.04/(5/3)), .1)

Coefficient_Vector %>%
  data.frame(name = namelist, value = .) %>%
  pivot_wider(everything()) %>%
  gt() %>%
  tab_header("Table S6: Population Coefficient Values") %>%
  fmt_number(columns = 1:4, decimals = 4)
```

### Sampled Values

This section implements the sampling for the 

```{r sampled-coeff}
Coefficient_Vector_Use <- 
  rnorm(4, Coefficient_Vector, .05)

Coefficient_Vector_Use %>%
  data.frame(name = namelist, value = .) %>%
  pivot_wider(everything()) %>%
  gt() %>%
  tab_header("Table S7: Sampled Coefficient Values") %>%
  fmt_number(columns = 1:4, decimals = 4)
```

The sampled coefficients varied from the population values as expected and happened to also follow the same ordinal pattern of $\beta_{ER} > \beta_{AS} > \beta_{SL} > \beta_{WE}$ as the population values.

### Generate Observations

This section implements generating J: the underlying Normal DV.

A linear regression predicting J using the four IVs is also implemented.

```{r gen-y-normal}
Data_Frame %<>%
  mutate(
    J = 
      ER*Coefficient_Vector[[1]] + AS*Coefficient_Vector[[2]] + 
      SL*Coefficient_Vector[[3]] + WE*Coefficient_Vector[[4]], 
    J = J + rnorm(total_n, 0, sqrt(1 - var(J)))
  )

Data_Frame %>%
  summarise("Mean" = mean(J)) %>% 
  bind_cols(
    Data_Frame %>%
      summarise("Standard Deviation" = sd(J))
  ) %>%
  bind_cols(
    Data_Frame %>% 
      cor %>% 
      as_tibble(rownames = "IV Name") %>%
      filter(`IV Name` == "J") %>%
      select(-J, -`IV Name`)
  ) %>%
  gt() %>%
  tab_header("Table S8: Underlying Dependent Variable Descriptive Statistics") %>%
  fmt_number(columns = 1:6, decimals = 4) %>%
  tab_spanner(columns = c(ER, AS, SL, WE), label = "Correlations") %>%
  tab_style(
    style = cell_borders(sides = "right"),
    locations = cells_body(columns = "Standard Deviation")
  )

Data_Frame %>%
  select(J) %>%
  ggplot(aes(x = J)) +
  stat_bin() +
  ggtitle("Figure Sa: Distribution of the Underlying Dependent Variable") +
  theme_light()

lm(J ~ ., data = Data_Frame) %>% 
  parameters() %>%
  select(-df_error, -CI) %>%
  rename(Low = "CI_low", High = "CI_high") %>%
  gt(rowname_col = "Parameter") %>%
  fmt_number(columns = 2:7, decimals = 4) %>%
  tab_spanner(columns = c(Low, High), label = "Confidence Interval") %>%
  tab_header("Table S9: Underlying Dependent Variable Linear Regression")
```

A couple of points to note about the J variable. The standard deviation depicted in Table S8 for J is, as expected, nearly 1. The correlations between the four IVs with J are all similar to one another with values around .4 despite.This too is as expected as the observed correlations between an IV and a DV are a function of a complex set of path analytic parameters combining each IV's known coefficient value (i.e., as observed in Table S2) with its correlation with each other variable as well as each other variable's known coefficient.

The results in Table S9 confirm that the population values in Table S6 were carried through to the data.

Figure Sa also depicts the distribution of J as observed in the data.

## Generate Poisson Dependent Variable

This section describes the translation of the underlying Normal variable J into the Poisson distributed SJ variable.

SJ is derived from J by first translating the Normal values to cumulative probabilities and, subsequently, translating those cumulative probabilities to Poisson quantiles assuming a mean of 1. A mean of 1 was chosen to make the SJ result as close to J as possible as both have variances of 1.	

```{r gen-y-poisson}
Data_Frame %<>%
  mutate(
    SJ = J %>% pnorm(log.p = TRUE) %>% qpois(1, log.p = TRUE)
  )

Data_Frame %>%
  summarise("Mean" = mean(SJ)) %>% 
  bind_cols(
    Data_Frame %>%
      summarise("Standard Deviation" = sd(SJ))
  ) %>%
  bind_cols(
    Data_Frame %>% 
      cor %>% 
      as_tibble(rownames = "IV Name") %>%
      filter(`IV Name` == "SJ") %>%
      select(-SJ, -J, -`IV Name`)
  ) %>%
  gt() %>%
  tab_header("Table S10: Poisson Dependent Variable Descriptive Statistics") %>%
  fmt_number(columns = 1:6, decimals = 4) %>%
  tab_spanner(columns = c(ER, AS, SL, WE), label = "Correlations") %>%
  tab_style(
    style = cell_borders(sides = "right"),
    locations = cells_body(columns = "Standard Deviation")
  )

Data_Frame %>%
  select(SJ) %>%
  ggplot(aes(x = SJ)) +
  stat_bin() +
  ggtitle("Figure Sb: Distribution of the Poisson Dependent Variable") +
  theme_light()
```

The results from Table S10 confirm expectations about the Poisson distributed variable's mean and standard deviation. SJ produced similar correlations with the IVs as the J variable on which it was based. The reduced correlation magnitudes among the IVs with SJ was due to the effect of partly discretizing the J variable into the SJ variable.

Figure Sb also shows the distribution of SJ variable.

## Generate Negative Binomial Dependent Variable

This section describes the translation of the underlying Normal variable J into the negative Binomial distributed MJ variable.

The generation of the MJ variable followed the same procedure as that to create SJ as it is created from the Normal cumulative probabilities of J then translated to negative Binomial quantiles assuming a _size_ of .5 and _mu_ parameter of 1.

The _size_ and _mu_ parameters were chosen to obtain a mean (i.e., the _mu_/$\mu$ value) of 1 to mirror the Poisson distribution but a variance that substantially exceeded 1; in this case  or a value of 3 as $\sigma^{2} = \mu + \frac{\mu^2}{size}$.

```{r gen-y-neg-bin}
Data_Frame %<>%
  mutate(
    MJ = J %>% pnorm(log.p = TRUE) %>% qnbinom(size = .5, mu = 1, log.p = TRUE)
  )

Data_Frame %>%
  summarise("Mean" = mean(MJ)) %>% 
  bind_cols(
    Data_Frame %>%
      summarise("Standard Deviation" = sd(MJ))
  ) %>%
  bind_cols(
    Data_Frame %>% 
      cor %>% 
      as_tibble(rownames = "IV Name") %>%
      filter(`IV Name` == "MJ") %>%
      select(-SJ, -J, -`IV Name`, -MJ)
  ) %>%
  gt() %>%
  tab_header("Table S11: Negative Binomial Dependent Variable Descriptive Statistics") %>%
  fmt_number(columns = 1:6, decimals = 4) %>%
  tab_spanner(columns = c(ER, AS, SL, WE), label = "Correlations") %>%
  tab_style(
    style = cell_borders(sides = "right"),
    locations = cells_body(columns = "Standard Deviation")
  )

Data_Frame %>%
  select(MJ) %>%
  ggplot(aes(x = MJ)) +
  stat_bin() +
  ggtitle("Figure Sc: Distribution of the Negative Binomial Dependent Variable") +
  theme_light()
```

The results from Table S11 confirm expectations about the negative Binomial distributed variable's mean and standard deviation ($\sigma_{MJ} = 1.757; \sigma^2_{MJ} = 3.087$; . MJ also produced similar correlations with the IVs as the J variable on which it was based but smaller values than SJ. The further reduced correlation magnitudes among the IVs with MJ was due to the effect of partly discretizing the J variable into the MJ variable paired with the strong skew introduced by the additional variance of the negatve binomial

Figure Sc also shows the distribution of MJ variable.

## Report Primary Generated Data Descriptives

This section produces Table 1 in the manuscript including the descriptive statistics for all four IVs and both DVs.

```{r display-observed-descriptives}
Data_Frame %>%
  summarise(across(everything(), mean)) %>%
  pivot_longer(everything(), names_to = "Variable", values_to = "Mean") %>%
  left_join(
    Data_Frame %>%
      summarise(across(everything(), sd)) %>%
      pivot_longer(everything(), names_to = "Variable", 
                   values_to = "Standard Deviation"),
    by = "Variable"
  ) %>%
  left_join(
    Data_Frame %>% 
      cor %>% 
      as_tibble(rownames = "Variable"),
    by = "Variable"
  ) %>%
  filter(Variable != "J") %>%
  select(-J) %>%
  gt() %>%
  tab_header("Table 1: Descriptive Statistics") %>%
  fmt_number(columns = 2:9, decimals = 4) %>%
  tab_spanner(columns = c(ER, AS, SL, WE, SJ, MJ), label = "Correlations") %>%
  tab_style(
    style = cell_borders(sides = "right"),
    locations = cells_body(columns = "Standard Deviation")
  ) %T>%
  print %>%
  gtsave(filename = "descrips_initial.tex", path = "./includes/")
```

```{r check-point-1-save, results='hide', include=FALSE}
saveRDS(Data_Frame, "./Data_Results/DF.rds")
```

## Poisson with Offset Dependent Variables

The dependent variables with an offset were generated assuming a Poisson distribution and two different versions of the Poisson-with-offset variables were created.

### Uncorrelated Offset

The Poisson variable with an offset is generated from a binomial distribution with the idea that the Poisson rate/mean parameter can be derived as $np = \lambda$.  In this case, the _n_ is 10 and the _p_ is .1 to obtain the mean of 1 (i.e., $10*.1 = 1$).

Given there are up to 10 trials, the offset is implemented as the number of trials actually realized for an observation.  This number of trials is obtained as an integer vector from 1 to 10 sampled randomly for all observations.

The number of 'successes' (i.e., the Poisson variable) is then implemented, as before, using the cumulative probability from the Normal variable as translated to a binomial quantile using the number of realized trials for each observation and a fixed probability of .1).

```{r offset-uncorrelated}
Data_Frame %<>%
  mutate(
    Number_Observed = sample(1:10, total_n, replace = TRUE)
  )

Data_Frame %>% select(Number_Observed) %>% 
  ggplot(aes(Number_Observed)) + stat_bin()

Data_Frame %<>%
  mutate(
    Y_Poisson_Offset = 
      qbinom(
        pnorm(Y_Normal, log.p = TRUE),
             Number_Observed, .1, log.p = TRUE
        )
  )

Data_Frame %>%
  select(Y_Poisson_Offset) %>%
  ggplot(aes(Y_Poisson_Offset)) + stat_bin()

Data_Frame %>%
  summarise(
    across(.fns = mean),
    ) 

Data_Frame %>%
  summarise(
    across(.fns = sd),
    ) 

Data_Frame %>% 
  cor %>% 
  kable

```

### Correlated Offset

The correlated offset variable is implemented in a way similar to the uncorrelated offset variable save for the way in which the number of realized trials was implemented for each observation.  

The number of realized trials was obtained by randomly sampling coefficients in the same way as for the development of the Normally distributed variable (4 draws from Normal distribution with the same set of means as the Normally distributed variable but randomized in order and negative and a standard deviation of .05) and generating a Normally distributed variable with a standard deviation of 1.  The newly generated Normally distributed variable is then translated into a cumulative probability and uniform distribution quantile with a minimum of 1 and maximum of 10.  

This new 1 to 10 count variable is then used as the number of realized trials in the same process used to generate an offset as was implemented above.

```{r correlated-offset}
Offset_Vector <- 
  rnorm(4, sample(c(.2, .15, .12, .1))*-1, .2)

Offset_Vector %>% kable

Data_Frame %<>%
  mutate(
    Censoring =
      IV1*Offset_Vector[[1]] + IV2*Offset_Vector[[2]] + 
      IV3*Offset_Vector[[3]] + IV4*Offset_Vector[[4]],
    Censoring = Censoring + rnorm(total_n, 0, sqrt(1 - var(Censoring)))
  )

Data_Frame %<>%
  mutate(
    N_obs_censor =
      qunif(
        pnorm(Censoring, log.p = TRUE), 
        1, 10, log.p = TRUE) %>% ceiling(),
    Y_Poisson_Censored = 
      qbinom(
        pnorm(Y_Normal, log.p = TRUE),
             N_obs_censor, .1, log.p = TRUE
        )
  )

Data_Frame %>% select(N_obs_censor) %>% 
  ggplot(aes(N_obs_censor)) + stat_bin()

Data_Frame %>%
  select(Y_Poisson_Censored) %>%
  ggplot(aes(Y_Poisson_Censored)) + stat_bin()

Data_Frame %>%
  summarise(
    across(.fns = mean),
    ) 

Data_Frame %>%
  summarise(
    across(.fns = sd),
    ) 

Data_Frame %>% 
  cor %>% 
  kable
```

## Zero-inflated Poisson Dependent Variable

The zero-inflated Poisson dependent variable uses the Poisson variable as well as the Normally distributed variable created to produce the correlated offset (negative, randomized Normal variable coefficients).  The correlated offset variable is translated through a cumulative Normal probability to a binomial quantile function with 1 draw and a probability of .9. 


```{r zero-inflate}
Data_Frame %<>%
  mutate(
    Y_ZIP = 
      Y_Poisson * 
      qbinom(
        pnorm(Censoring, log.p = TRUE),
        1, .9, log.p = TRUE)
  )

Data_Frame %>%
  select(Y_ZIP) %>%
  ggplot(aes(Y_ZIP)) + stat_bin()

Data_Frame %>%
  summarise(
    across(.fns = mean),
    ) 

Data_Frame %>%
  summarise(
    across(.fns = sd),
    ) 

Data_Frame %>% 
  cor %>% 
  kable

```

```{r load-data, results='hide', include=FALSE}
Data_Frame <- 
  readRDS("./Data_Results/DF.rds")
```

# Primary Modeling

This section describes the model estimation and dominance analysis of the primary analysis models involving SJ and MJ variables.

This section also sets the deviance $R^2$ function (i.e., `dev_r2`) needed for dominance analysis.

```{r dev-R2}
dev_r2 <-
  function(obj) {
    res <- (1 - obj$deviance/obj$null.deviance)
    names(res) <- "dev_r2"
    return(res)
  }
```

## Poisson Regressions

This section's focus is on obtaining all modeling results associated with the PR using SJ as DV.

### Obtain Modeling Results

This section estimates and reports on the PR results. An IRR and standardized computation are also included.

These results form Table 2 of the manuscript.

```{r SJ-pois-reg}
SJ_pois_reg <- 
  glm(SJ ~ ER + AS + SL + WE, 
      data = Data_Frame, 
      family = poisson()) 

SJ_pois_reg_unstd <- 
  SJ_pois_reg %>% 
  parameters() 

SJ_pois_reg_std <- 
  SJ_pois_reg %>%
  standardise_parameters(method = "basic")

SJ_pois_reg_unstd  %>% 
  select(-df_error, -CI) %>%
  rename(Low = "CI_low", High = "CI_high") %>%
  mutate(IRR = exp(Coefficient)) %>%
  left_join(
    SJ_pois_reg_std %>% 
      select(Parameter, Std_Coefficient) %>%
      rename(Standardized = "Std_Coefficient"),
    by = "Parameter") %>%
  gt(rowname_col = "Parameter") %>%
  fmt_number(columns = 2:9, decimals = 4) %>%
  tab_spanner(columns = c(Low, High), label = "Confidence Interval") %>%
  tab_header("Table 2: Poisson Regression") %>% 
  tab_style(
    style = cell_borders(sides = "right"),
    locations = cells_body(columns = "p")
  ) %T>%
  print %>%
  gtsave(filename = "poisson_coeff.tex", path = "./includes/")
```

The results in Table 2 echo those of Table S9 in that the obtained coefficients are derived directly from the results reported on in Table S7---with a translation to a Poisson, log-linear model scale. 

### Obtain All Subsets R-square

This section captures each Poisson model subset's $R^2$ value associated with a specific set of IVs.

```{r SJ-pois-reg-subsets}
IV_subsets <- 
  expand_grid(c("ER", ""), c("AS", ""), c("SL", ""), c("WE", "")) %>%
  set_names(c("ER", "AS", "SL", "WE")) %>%
  mutate(num_per = rowSums(across(.fns = ~ str_length(.) > 1))) %>%
  arrange(num_per, desc(ER), desc(AS), desc(SL), desc(WE)) %>%
  select(-num_per) %>%
  slice(-1) %>% 
  t() %>%
  as_tibble() 

SJ_pois_subsets <-
  map_dbl(IV_subsets,
          \(ivs) {
            discard(ivs, ~ str_length(.) < 2) %>%
            reformulate(response = "SJ") %>%
              glm(data = Data_Frame, family = poisson()) %>%
              dev_r2()
          }
  )

IV_subset_names <-
  map_chr(IV_subsets, 
          \(ivs) {
            discard(ivs, ~ str_length(.) < 2) %>%
            str_c(., collapse = " + ")
          }
  )

IV_subset_names %>% 
  as_tibble() %>%
  bind_cols(SJ_pois_subsets) %>%
  set_names(c("variable", "SJ")) %>%
  gt(rowname_col = "variable") %>%
  tab_header("Table S..: All Subsets Deviance R-square Poisson Models") %>%
  fmt_number(columns = 2, decimals = 4)
```

These results help to explain the observed complete dominance results and will be used in the manuscript to demonstrate specific computations.

### Dominance Analytic Results

This section captures the dominance analytic results for the Poisson modeling.

```{r SJ-pois-DA}
SJ_pois_DA <-
  domir(SJ ~ ER + AS + SL + WE, 
        \(fml, ...) {
          res <- 
            glm(fml, ...) 
          return(dev_r2(res))
        },
        data = Data_Frame, family = poisson())

SJ_pois_DA %>% 
  pluck("General_Dominance") %>%
  as_tibble(rownames = "Variable") %>%
  left_join(SJ_pois_DA %>% 
              pluck("Standardized") %>%
              as_tibble(rownames = "Variable"),
            by = "Variable") %>%
  set_names(c("Variable", "General Dominance", "Standardized")) %>%
  gt(rowname_col = "Variable") %>%
  tab_header("Table S..: Poisson Model General Dominance Statistics") %>%
  fmt_number(columns = 2:3, decimals = 4) %>%
  tab_source_note(str_c("Overall Deviance R-square is ", 
                        SJ_pois_reg %>% dev_r2() %>% format(digits = 4), "."))
```

The PR-based general dominance statistics in Table S.. show that the dominance hierarchy among IVs do not show large differences as all four IVs have relatively similar general dominance statistics. This result is not unexpected given the design of the population-level effects.

The sampled results' dominance hierarchy show that AS is most important (i.e., generally dominates all others), followed by ER, then SL, and finally WE (i.e., generally dominated by all others).

The standardized values express the general dominance statistics as a proportion of the $R^2$.

## Negative Binomial Regressions

This section's focus is on obtaining all modeling results associated with the NBR using MJ as DV.

### Obtain Modeling Results

This section estimates and reports on the NBR results. As with the PR, an IRR and standardized computation are also included. Additionally, the Theta parameter is included in a footnote.

These results form Table 3 of the manuscript.

```{r MJ-nb-reg}
MJ_nb_reg <- 
  glm.nb(MJ ~ ER + AS + SL + WE, 
      data = Data_Frame) 

MJ_nb_reg_unstd <- 
  MJ_nb_reg %>% 
  parameters() 

MJ_nb_reg_std <- 
  MJ_nb_reg %>%
  standardise_parameters(method = "basic")

MJ_nb_reg_unstd  %>% 
  select(-df_error, -CI) %>%
  rename(Low = "CI_low", High = "CI_high") %>%
  mutate(IRR = exp(Coefficient)) %>%
  left_join(
    MJ_nb_reg_std %>% 
      select(Parameter, Std_Coefficient) %>%
      rename(Standardized = "Std_Coefficient"),
    by = "Parameter") %>%
  gt(rowname_col = "Parameter") %>%
  fmt_number(columns = 2:9, decimals = 4) %>%
  tab_spanner(columns = c(Low, High), label = "Confidence Interval") %>%
  tab_header("Table 3: Negative Binomial Regression") %>% 
  tab_style(
    style = cell_borders(sides = "right"),
    locations = cells_body(columns = "p") 
  ) %>%
  tab_source_note(str_c("Theta parameter is ", 
                        MJ_nb_reg$theta %>% 
                          format(big.mark = ",", digits = 4), ".")) %T>%
  print %>%
  gtsave(filename = "nb_coeff.tex", path = "./includes/")
```

The results in Table 3 again echo those of Table S9 in that the obtained coefficients are derived directly from the results reported on in Table S7. The results are also relatively similar to Table 2 with the exception of larger values across all coefficients and a slightly different rank order of the standardized results.

### Obtain All Subsets R-square

This section captures each negative Binomial model subset's $R^2$ value associated with a specific set of IVs.

```{r MJ-nb-reg-subsets}
MJ_nb_subsets <-
  map_dbl(IV_subsets, 
          \(ivs) {
            discard(ivs, ~ str_length(.) < 2) %>%
            reformulate(response = "MJ") %>%
              glm.nb(data = Data_Frame) %>%
              dev_r2()
          }
  )

IV_subset_names %>% 
  as_tibble() %>%
  bind_cols(MJ_nb_subsets) %>%
  set_names(c("variable", "MJ")) %>%
  gt(rowname_col = "variable") %>%
  tab_header("Table S..: All Subsets Deviance R-square Negative Binomial Models") %>%
  fmt_number(columns = 2, decimals = 4)
```

As with the individual PR results, the NBR results are used for computations and explaining the pattern of complete dominance results.

### Dominance Analytic Results

This section captures the dominance analytic results for the negative Binomial modeling.

```{r MJ-nb-DA}
MJ_nb_DA <-
  domir(MJ ~ ER + AS + SL + WE, 
        \(fml, ...) {
          res <- 
            glm.nb(fml, ...) 
          return(dev_r2(res, null))
        },
        data = Data_Frame)

MJ_nb_DA %>% 
  pluck("General_Dominance") %>%
  as_tibble(rownames = "Variable") %>%
  left_join(MJ_nb_DA %>% 
              pluck("Standardized") %>%
              as_tibble(rownames = "Variable"),
            by = "Variable") %>%
  set_names(c("Variable", "General Dominance", "Standardized")) %>%
  gt(rowname_col = "Variable") %>%
  tab_header("Table S..: Negative Binomial Model General Dominance Statistics") %>%
  fmt_number(columns = 2:3, decimals = 4) %>%
  tab_source_note(str_c("Overall Deviance R-square is ", 
                        MJ_nb_reg %>% dev_r2() %>% format(digits = 4), "."))
```

The NBR-based DA results are quite similar to those obtained for the PR-based results with the exception of the rank order change between SL and WE with WE being more important for the NBR than SL.

<!-- # ~~~ NB regs don't work with dominance_analysis() - method dispatch issue? -->
<!-- # ~~~ they have r2() method but DA doesn't recognize it -->
<!-- # nb_result %>% -->
<!-- #   dominance_analysis() -->

## Combined All Subsets Reporting

This section captures all PR and NBR subsets

Table 3 in the manuscript is produced in this section.

```{r comb-subsets-display}
IV_subset_names %>% 
  as_tibble() %>%
  bind_cols(SJ_pois_subsets) %>%
  bind_cols(MJ_nb_subsets) %>%
  set_names(c("variable", "Poisson/SJ", "Negative Binomial/MJ")) %>%
  gt(rowname_col = "variable") %>%
  tab_header("Table 3: All Subsets Deviance R-square Results Across Models") %>%
  fmt_number(columns = 2:3, decimals = 4) %T>%
  print() %>%
  gtsave(filename = "all_subsets.tex", path = "./includes/")
```

## Combined General Dominance Reporting

This section captures the general dominance analysis reporting.

Table 4 in the manuscript is generated in this section.

```{r gend-dom-display}
SJ_pois_DA %>% 
  pluck("General_Dominance") %>%
  as_tibble(rownames = "Variable") %>%
  left_join(MJ_nb_DA %>% 
              pluck("General_Dominance") %>%
              as_tibble(rownames = "Variable"),
            by = "Variable") %>%
  set_names(c("Variable", "Poisson/SJ", "Negative Binomial/MJ")) %>%
  bind_rows(tibble(Variable = "Overall", 
                   `Poisson/SJ` = SJ_pois_reg %>% dev_r2(), 
                   `Negative Binomial/MJ` = MJ_nb_reg %>% dev_r2())) %>%
  gt(rowname_col = "Variable") %>%
  tab_header("Table 4: General Dominance Statistics") %>%
  tab_style(
    style = cell_borders(sides = "bottom"),
    locations = cells_body(rows = 4)
  ) %>%
  fmt_number(columns = 2:3, decimals = 4) %T>%
  print %>%
  gtsave(filename = "gen_dom.tex", path = "./includes/")
```

## Conditional Dominance Graphic Reporting

```{r condit-domin-display}
lm_da %>%
  pluck(2) %>%
  mutate(Model = "Normal") %>%
  bind_rows(
    poisson_da$Conditional_Dominance %>%
      as_tibble(rownames = "Subset") %>%
      rename_with(
        .fn = ~ str_replace_all(., "subset_size", "IVs"),
        .cols = starts_with("subset")
      ) %>%
      mutate(Model = "Poisson")
  ) %>%
  pivot_longer(
    cols = starts_with("IVs"),
    names_to = "IVs",
    values_to = "R2",
    names_prefix = "IVs_"
    ) %>%
  ggplot(
    aes(x = IVs, y = R2, group = Subset, linetype = Subset)
  ) + geom_line() + 
  facet_grid(rows = vars(Model)) + theme_linedraw()

ggsave("condit_gph.png", height = 4, width = 6, 
       units = "in", path = "./includes/")
```

# Offset Modeling

## Wrong Poisson

```{r}
poisson_result_offset_wrong <- 
  glm(Y_Poisson_Offset ~ IV1 + IV2 + IV3 + IV4, data = Data_Frame, 
      family = poisson())

poisson_result_offset_wrong %>% 
  parameters()

poisson_result_offset_wrong %>%
  standardise_parameters(method = "basic")

domir(Y_Poisson_Offset ~ IV1 + IV2 + IV3 + IV4, 
      \(fml,...) {
        res <- glm(fml, ...) 
        ret <- r2(res)[[1]]
      }
      ,
      data = Data_Frame, family = poisson()) 
```

## Right Poisson

```{r}
poisson_result_offset_right <- 
  glm(Y_Poisson_Offset ~IV1 + IV2 + IV3 + IV4 + offset(log(Number_Observed)), data = Data_Frame, 
      family = poisson())

poisson_result_offset_right %>% 
  parameters()

poisson_result_offset_right %>%
  standardise_parameters(method = "basic")

domir(Y_Poisson_Offset ~ IV1 + IV2 + IV3 + IV4, 
      \(fml,...) {
        fml2 <- update(fml, . ~ . + offset(log(Number_Observed)))
        res <- glm(fml2, ...) 
        ret <- r2(res)[[1]]
      }
      ,
      data = Data_Frame, family = poisson()) 
```



## Wrong Poisson C

```{r}
poisson_result_cens_wrong <- 
  glm(Y_Poisson_Censored ~ IV1 + IV2 + IV3 + IV4, data = Data_Frame, 
      family = poisson())

poisson_result_cens_wrong %>% 
  parameters()

poisson_result_cens_wrong %>%
  standardise_parameters(method = "basic")

domir(Y_Poisson_Censored ~ IV1 + IV2 + IV3 + IV4, 
      \(fml,...) {
        res <- glm(fml, ...) 
        ret <- r2(res)[[1]]
      }
      ,
      data = Data_Frame, family = poisson()) 
```

## Right Poisson C

```{r}
poisson_result_cens_right <- 
  glm(Y_Poisson_Censored ~IV1 + IV2 + IV3 + IV4 + offset(log(N_obs_censor)), data = Data_Frame, 
      family = poisson())

poisson_result_cens_right %>% 
  parameters()

poisson_result_cens_right %>%
  standardise_parameters(method = "basic")

domir(Y_Poisson_Censored ~ IV1 + IV2 + IV3 + IV4, 
      \(fml,...) {
        fml2 <- update(fml, . ~ . + offset(log(N_obs_censor)))
        res <- glm(fml2, ...) 
        ret <- r2(res)[[1]]
      }
      ,
      data = Data_Frame, family = poisson()) 
```

# Zero-Inflation

```{r}
zip_result <- 
  zeroinfl(Y_ZIP ~ IV1 + IV2 + IV3 + IV4 | IV1 + IV2 + IV3 + IV4, 
           data = Data_Frame)

zip_result %>% 
  parameters()

zip_result %>%
  standardise_parameters(method = "basic")
```

## IV DA

```{r}
domir(Y_ZIP ~ IV1 + IV2 + IV3 + IV4, 
      \(fml,...) {
        fml2 <- update(fml, . ~ .)
        res <- zeroinfl(fml2, ...) 
        ret <- r2(res)[[1]]
      }
      ,
      data = Data_Frame) 
```

# Records and Reproducibility

```{r}
sessionInfo()
```

The random seed information used in this session:

    84490856
    Min: 1, Max: 99999999
    2022-08-14 14:50:02 UTC
    Random.org
