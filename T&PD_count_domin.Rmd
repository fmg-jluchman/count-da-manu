---
title: Count Regression Model Dominance Analysis
subtitle: Documentation
#author: Joseph Luchman
author: Anonymized for review
output: html_notebook
editor_options: 
  markdown: 
    wrap: 72
---

This notebook provides documentation for the generation of the data used in the manuscript **Relative Importance Analysis with Count Regression Models**.

The documentation and discussion of approach in this document extends on that provided in the main manuscript as the discussion here focuses more closely on implementation details. These implementation details are are not essential for the reader to understand the manuscript but are essential for understanding the analytic context and for reproducibility.

The code block below initiates the analysis by setting the R environment.

A component of this environment is the random seed to be able to fully reproduce the data. 

Details on the random seed as well as the details of the R environment are available at the end of this notebook.

```{r set-up, results='hide'}
library(gt)
library(knitr)
library(kableExtra)
library(MASS)
library(pscl)
library(tidyverse)
library(magrittr)
library(domir)
library(parameters)
library(datawizard)
library(MCMCpack)

set.seed(84490856)
```

# Data Generation

The manuscript describes four IVs including:

  a. equipment reliability or _ER_
  b. assistant staffing levels or _AS_
  c. tailor skill-level or _SL_
  d. tailor work experience or _WE_
  
This section provides details related to the population-level parameters used to generate the data used for analysis.

## Generate IV Data

The generation of the four IVs begins with setting up a population-level covariance matrix describing the variances of and interrelationships between the IVs.

The four IVs were designed such that they would have different variances. The variances chosen were four equally spaced values between standard deviation values of 1 and 2. The first IV, _ER_, was then designed to have a $\sigma_{ER} = 1.00$ and $\sigma^2_{ER} = 1.00$.The second IV, _AS_, was designed to have $\sigma_{AS} = 1.33$ and of $\sigma^2_{AS} = 1.78$.  _SL_ was designed to have $\sigma_{SL} = 1.67$ and $\sigma^2_{SL} = 2.78$.  Finally, _WE_ was designed to have $\sigma_{WE} = 2.00$ and $\sigma^2_{WE} = 4.00$.

The design of the interrelationships between the IVs was implemented as to give the IVs non-zero overlaps between one another. This was done as DA is most useful, as a methodology for inferring importance, when the IVs overlap. Although the IVs were designed to overlap, I did not want the extent of the overlap between the IVs to be such that some IVs were more redundant with other IVs than other IVs. All six correlations between the four IVs were thus designed to take on one of three values .250, .125, and .063. These three values were "balanced" across IVs such that the total redundancy for any one IV was identical to the others. 

The six different correlations specified were: $r_{ER,AS} = .250$, $r_{ER,SL} = .125$, $r_{ER,WE} = .063$, $r_{AS,SL} = .063$, $r_{AS,WE} = .125$, and $r_{SL,WE} = .250$.

The manuscript notes that a goal for the generation of the data for analytic use in this exercise is to obtain data that are 'realistic.' The balanced correlations that are determined at the population-level fail to 'feel real.' 

In an effort to add more realism to the dataset, the population covariance matrix is filtered through an inverse Wishart distribution using a single draw and large value (i.e., 100) for the degree of freedom parameter.

Sampling from the inverse Wishart distribution will produce a set of correlation values that are based on the balanced approach but appear more 'as though' they were generated by a real data generating process. The large value for the degrees of freedom has the effect of reducing the variances of the sampled matrix but also stabilizes the correlations of the values sampled to be closer to the population values. The variances of all the variables, once generated in the data, are multiplied by 100 to re-adjust them back to near their original values.

### Population Values

This section sets the population-level covariance matrix.

```{r gen-iv-mat}
namelist <- 
  c("ER", "AS", "SL", "WE")

Covariance_Matrix <- 
  c(1, .5^(2:4)*sqrt(1*c((4/3)^2, (5/3)^2, 4))*sqrt(1),
    .5^2*sqrt(1)*sqrt(1*(4/3)^2), (4/3)^2, .5^(4:3)*sqrt(1*(4/3)^2)*sqrt(1*c((5/3)^2, 4)),
    .5^(3:4)*sqrt(1*(5/3)^2)*sqrt(1*c(1, (4/3)^2)), (5/3)^2, .5^2*sqrt(1*(5/3)^2)*sqrt(1*4),
    .5^(4:2)*sqrt(1*4)*sqrt(1*c(1, (4/3)^2, (5/3)^2)), 4) %>%
  matrix(nrow = 4, byrow = TRUE)

Covariance_Matrix %>% 
  as.data.frame() %>%
  set_names(namelist) %>%
  set_rownames(namelist) %>%
  gt(rownames_to_stub = TRUE) %>%
  tab_header("Table S1: Population Covariance Matrix") %>%
  fmt_number(columns = 2:5, decimals = 4)

Covariance_Matrix %>% cov2cor() %>% 
  as.data.frame() %>%
  set_names(namelist) %>%  
  set_rownames(namelist) %>%
  gt(rownames_to_stub = TRUE) %>%
  tab_header("Table S2: Population Correlation Matrix")
```

Tables S1 and S2 confirm the correct/intended values are in the covariance and correlation matrices.

### Sampled Values

This section uses the set population covariance matrix as the scale parameter and a value of 100 as a degree of freedom parameter to obtain a single draw from the inverse Wishart distribution.  

The important component obtained by this sampled matrix is the correlations it produces. The covariance matrix will be updated/rescaled once the data are generated.

```{r sample-iv-mat}
Covariance_Matrix_Use <- 
  riwish(100, Covariance_Matrix)

Covariance_Matrix_Use %>% 
  as.data.frame() %>%
  set_names(namelist) %>%
  set_rownames(namelist) %>%
  gt(rownames_to_stub = TRUE) %>%
  tab_header("Table S3: Sampled Covariance Matrix") %>%
  fmt_number(columns = 2:5, decimals = 4)

Covariance_Matrix_Use %>% cov2cor() %>% 
  as.data.frame() %>%
  set_names(namelist) %>%  
  set_rownames(namelist) %>%
  gt(rownames_to_stub = TRUE) %>%
  tab_header("Table S4: Sampled Correlation Matrix") %>%
  fmt_number(columns = 2:5, decimals = 4)
```

There are a few points of note about the sampled results from Tables S3 and S4.  

As was expected, the variances for the four IVs have shrunk substantially moving from the population to the sampled matrix. Again, the change in the variance will be corrected to a values more similar to the population values once the data are generated. Note that the relative differences between the variances maintained the population-level pattern with $\sigma^2_{WE} > \sigma^2_{SL} > \sigma^2_{AS} > \sigma^2_{ER}$.

The correlations obtained by the sampled matrix also appear plausible for behavioral science data.

### Generate Observations

This section discusses the generation of the simulated multivariate Normal data using the sampled covariance matrix. The means of the variables were set at zero.

The sample size of the generated data were also determined through a random process. Specifically, the value was a draw from a random uniform distribution falling between 5,000 and 10,000 rounded to the nearest integer. The range chosen was expected to result in a sufficiently large sample size for the data analysis demonstration yet also be 'realistic.'

```{r gen-iv-data}
total_n <- 
  runif(n = 1, min = 5000, max = 10000) %>% 
  round()

Data_Frame <- 
  mvrnorm(n = total_n, 
          mu = rep(0, times = 4), 
          Sigma = Covariance_Matrix_Use) %>% 
  as.data.frame() %>%
  multiply_by(10) %>%
  set_names(namelist)

Data_Frame %>%
  summarise(
    across(.fns = mean),
    ) %>% 
  pivot_longer(everything(), names_to = "IV Name", values_to = "Mean") %>%
  left_join(
  Data_Frame %>%
  summarise(
    across(.fns = sd),
    ) %>% pivot_longer(everything(), names_to = "IV Name", 
                       values_to = "Standard Deviation")
  ) %>%
  left_join(
    Data_Frame %>% 
      cor %>% 
      as_tibble(rownames = "IV Name")
  ) %>%
  gt(rowname_col = "IV Name") %>%
  tab_header("Table S5: Sampled Data Descriptive Statistics") %>%
  fmt_number(columns = 2:7, decimals = 4) %>%
  tab_spanner(columns = c(ER, AS, SL, WE), label = "Correlations") %>%
  tab_style(
    style = cell_borders(sides = "right"),
    locations = cells_body(columns = "Standard Deviation")
  ) %>%
  tab_source_note(str_c("Sample Size of Simulated Data is ", 
                        nrow(Data_Frame) %>% format(big.mark = ","), "."))
  

```

A total of 6,870 multivariate Normally distributed observations were simulated for this data analysis.

The variances of each of the IVs, as noted above, were re-adjusted to closer to the original, population-level range.

## Generate Underlying Normally Distributed Dependent Variable

The generation of the number of stock jackets produced (SJ; Poisson distributed) and number of made-to-measure jackets produced (MJ; negative Binomial distributed) by the tailors, both DVs for the primary analyses, began with generating a single Normally distributed variable from which both were derived.

The underlying Normally distributed variable was generated as a linear combination of the four IVs.

Four population-level coefficient values were chosen for this variable were: $\beta_{ER} =.200$,  $\beta_{AS} =.173$,  $\beta_{SL} =.155$, $\beta_{WE} =.100$. These four values were chosen as they each, when squared and multiplied by the population-level variance, would produce a value of .04---not considering IV intercorrelations.

The coefficient values used for the generated underlying jackets variable (J) were sampled in a single draw from a Normal distribution with the four population values used as means. Each mean had a shared standard deviation of .05 to add variation to the coefficient values.

The error variance for J was set to be $1 - \sigma^2_{J}$ thus forcing the variance of J to be 1. The mean of J is also set to be 0.
	
### Population Values

This section sets the population coefficient values.

```{r pop-coefs}
Coefficient_Vector <- 
  c(.2, sqrt(.04/(4/3)), sqrt(.04/(5/3)), .1)

Coefficient_Vector %>%
  data.frame(name = namelist, value = .) %>%
  pivot_wider(everything()) %>%
  gt() %>%
  tab_header("Table S6: Population Coefficient Values") %>%
  fmt_number(columns = 1:4, decimals = 4)
```

### Sampled Values

This section implements the sampling for the 

```{r sampled-coeff}
Coefficient_Vector_Use <- 
  rnorm(4, Coefficient_Vector, .05)

Coefficient_Vector_Use %>%
  data.frame(name = namelist, value = .) %>%
  pivot_wider(everything()) %>%
  gt() %>%
  tab_header("Table S7: Sampled Coefficient Values") %>%
  fmt_number(columns = 1:4, decimals = 4)
```

The sampled coefficients varied from the population values as expected and happened to also follow the same ordinal pattern of $\beta_{ER} > \beta_{AS} > \beta_{SL} > \beta_{WE}$ as the population values.

### Generate Observations

This section implements generating J: the underlying Normal DV.

A linear regression predicting J using the four IVs is also implemented.

```{r gen-y-normal}
Data_Frame %<>%
  mutate(
    J = 
      ER*Coefficient_Vector_Use[[1]] + AS*Coefficient_Vector_Use[[2]] + 
      SL*Coefficient_Vector_Use[[3]] + WE*Coefficient_Vector_Use[[4]], 
    J = J + rnorm(total_n, 0, sqrt(1 - var(J)))
  )

Data_Frame %>%
  summarise("Mean" = mean(J)) %>% 
  bind_cols(
    Data_Frame %>%
      summarise("Standard Deviation" = sd(J))
  ) %>%
  bind_cols(
    Data_Frame %>% 
      cor %>% 
      as_tibble(rownames = "IV Name") %>%
      filter(`IV Name` == "J") %>%
      select(-J, -`IV Name`)
  ) %>%
  gt() %>%
  tab_header("Table S8: Underlying Dependent Variable Descriptive Statistics") %>%
  fmt_number(columns = 1:6, decimals = 4) %>%
  tab_spanner(columns = c(ER, AS, SL, WE), label = "Correlations") %>%
  tab_style(
    style = cell_borders(sides = "right"),
    locations = cells_body(columns = "Standard Deviation")
  )

Data_Frame %>%
  select(J) %>%
  ggplot(aes(x = J)) +
  stat_bin() +
  ggtitle("Figure Sa: Distribution of the Underlying Dependent Variable") +
  theme_light()

lm(J ~ ., data = Data_Frame) %>% 
  parameters() %>%
  select(-df_error, -CI) %>%
  rename(Low = "CI_low", High = "CI_high") %>%
  gt(rowname_col = "Parameter") %>%
  fmt_number(columns = 2:7, decimals = 4) %>%
  tab_spanner(columns = c(Low, High), label = "Confidence Interval") %>%
  tab_header("Table S9: Underlying Dependent Variable Linear Regression")
```

A couple of points to note about the J variable. The standard deviation depicted in Table S8 for J is, as expected, nearly 1. The correlations between the four IVs with J are all similar to one another with values around .4 despite. This too is as expected as the observed correlations between an IV and a DV are a function of a complex set of path analytic parameters combining each IV's known coefficient value (i.e., as observed in Table S2) with its correlation with each other variable as well as each other variable's known coefficient.

The results in Table S9 confirm that the population values in Table S6 were carried through to the data.

Figure Sa also depicts the distribution of J as observed in the data.

## Generate Poisson Dependent Variable

This section describes the translation of the underlying Normal variable J into the Poisson distributed SJ variable.

SJ is derived from J by first translating the Normal values to cumulative probabilities and, subsequently, translating those cumulative probabilities to Poisson quantiles assuming a mean of 1. A mean of 1 was chosen to make the SJ result as close to J as possible as both have variances of 1.	

```{r gen-y-poisson}
Data_Frame %<>%
  mutate(
    SJ = J %>% pnorm(log.p = TRUE) %>% qpois(1, log.p = TRUE)
  )

Data_Frame %>%
  summarise("Mean" = mean(SJ)) %>% 
  bind_cols(
    Data_Frame %>%
      summarise("Standard Deviation" = sd(SJ))
  ) %>%
  bind_cols(
    Data_Frame %>% 
      cor %>% 
      as_tibble(rownames = "IV Name") %>%
      filter(`IV Name` == "SJ") %>%
      select(-SJ, -J, -`IV Name`)
  ) %>%
  gt() %>%
  tab_header("Table S10: Poisson Dependent Variable Descriptive Statistics") %>%
  fmt_number(columns = 1:6, decimals = 4) %>%
  tab_spanner(columns = c(ER, AS, SL, WE), label = "Correlations") %>%
  tab_style(
    style = cell_borders(sides = "right"),
    locations = cells_body(columns = "Standard Deviation")
  )

Data_Frame %>%
  select(SJ) %>%
  ggplot(aes(x = SJ)) +
  stat_bin() +
  ggtitle("Figure Sb: Distribution of the Poisson Dependent Variable") +
  theme_light()
```

The results from Table S10 confirm expectations about the Poisson distributed variable's mean and standard deviation. SJ produced similar correlations with the IVs as the J variable on which it was based. The reduced correlation magnitudes among the IVs with SJ was due to the effect of partly discretizing the J variable into the SJ variable.

Figure Sb also shows the distribution of SJ variable.

## Generate Negative Binomial Dependent Variable

This section describes the translation of the underlying Normal variable J into the negative Binomial distributed MJ variable.

The generation of the MJ variable followed the same procedure as that to create SJ as it is created from the Normal cumulative probabilities of J then translated to negative Binomial quantiles assuming a _size_ of .5 and _mu_ parameter of 1.

The _size_ and _mu_ parameters were chosen to obtain a mean (i.e., the _mu_/$\mu$ value) of 1 to mirror the Poisson distribution but a variance that substantially exceeded 1; in this case  or a value of 3 as $\sigma^{2} = \mu + \frac{\mu^2}{size}$.

```{r gen-y-neg-bin}
Data_Frame %<>%
  mutate(
    MJ = J %>% pnorm(log.p = TRUE) %>% qnbinom(size = .5, mu = 1, log.p = TRUE)
  )

Data_Frame %>%
  summarise("Mean" = mean(MJ)) %>% 
  bind_cols(
    Data_Frame %>%
      summarise("Standard Deviation" = sd(MJ))
  ) %>%
  bind_cols(
    Data_Frame %>% 
      cor %>% 
      as_tibble(rownames = "IV Name") %>%
      filter(`IV Name` == "MJ") %>%
      select(-SJ, -J, -`IV Name`, -MJ)
  ) %>%
  gt() %>%
  tab_header("Table S11: Negative Binomial Dependent Variable Descriptive Statistics") %>%
  fmt_number(columns = 1:6, decimals = 4) %>%
  tab_spanner(columns = c(ER, AS, SL, WE), label = "Correlations") %>%
  tab_style(
    style = cell_borders(sides = "right"),
    locations = cells_body(columns = "Standard Deviation")
  )

Data_Frame %>%
  select(MJ) %>%
  ggplot(aes(x = MJ)) +
  stat_bin() +
  ggtitle("Figure Sc: Distribution of the Negative Binomial Dependent Variable") +
  theme_light()
```

The results from Table S11 confirm expectations about the negative Binomial distributed variable's mean and standard deviation ($\sigma_{MJ} = 1.757; \sigma^2_{MJ} = 3.087$; . MJ also produced similar correlations with the IVs as the J variable on which it was based but smaller values than SJ. The further reduced correlation magnitudes among the IVs with MJ was due to the effect of partly discretizing the J variable into the MJ variable paired with the strong skew introduced by the additional variance of the negatve binomial

Figure Sc also shows the distribution of MJ variable.

## Report Primary Generated Data Descriptives

This section produces Table 1 in the manuscript including the descriptive statistics for all four IVs and both DVs.

```{r display-observed-descriptives}
Data_Frame %>%
  summarise(across(everything(), mean)) %>%
  pivot_longer(everything(), names_to = "Variable", values_to = "Mean") %>%
  left_join(
    Data_Frame %>%
      summarise(across(everything(), sd)) %>%
      pivot_longer(everything(), names_to = "Variable", 
                   values_to = "Standard Deviation"),
    by = "Variable"
  ) %>%
  left_join(
    Data_Frame %>% 
      cor %>% 
      as_tibble(rownames = "Variable"),
    by = "Variable"
  ) %>%
  filter(Variable != "J") %>%
  select(-J) %>%
  gt() %>%
  tab_header("Table 1: Descriptive Statistics") %>%
  fmt_number(columns = 2:9, decimals = 4) %>%
  tab_spanner(columns = c(ER, AS, SL, WE, SJ, MJ), label = "Correlations") %>%
  tab_style(
    style = cell_borders(sides = "right"),
    locations = cells_body(columns = "Standard Deviation")
  ) %T>%
  print %>%
  gtsave(filename = "descrips_initial.tex", path = "./includes/")
```

## Poisson with Offset Dependent Variables

The manuscript also describes two other variables: x1 and x2.

These two variables are variants of SJ where part of the time period in generating the count dependent variable is lost or unrecorded.

### Uncorrelated Offset Dependent Variable

This section describes the process of generating the Poisson distributed, uncorrleated offset dependent variable.

This count variable is generated as multiple trials if a binomial distribution. Repeated trials from a binomial distribution are known to be Poisson distributed with a rate/mean parameter that can be derived as $np = \lambda$ where In this case the _n_ is the number of trials and _p_ is the probability of the event occurring. Thus, to generate a Poisson distribution to approximate SJ, I could set the binomial distibution to have an _n_ of 10 and a _p_ of .1 to obtain the mean of 1 (i.e., $10*.1 = 1$).

Adjusting the SJ-based binomial distribution to incorporate different 'exposure' time is then a matter of adjusting the _n_ parameter for each tailor. For this version of the variable, a random, uniformly distributed integer from 1 to 10 is sampled randomly for all tailors to represent the _n_ value.

Note that z1, the factor by which the Poisson variable is 'offset,' is retained for modeling.

```{r offset-uncorrelated}
Data_Frame %<>%
  mutate(
    z1 = sample(1:10, total_n, replace = TRUE),
    x1 = 
      J %>% pnorm(log.p = TRUE) %>%
      qbinom(z1, .1, log.p = TRUE)
  )

Data_Frame %>%
  summarise("Mean" = mean(x1)) %>% 
  bind_cols(
    Data_Frame %>%
      summarise("Standard Deviation" = sd(x1))
  ) %>%
  bind_cols(
    Data_Frame %>% 
      cor %>% 
      as_tibble(rownames = "IV Name") %>%
      filter(`IV Name` == "x1") %>%
      select(-SJ, -J, -`IV Name`, -MJ, -x1, -z1)
  ) %>%
  gt() %>%
  tab_header("Table S12: Uncorrelated Offset Poisson Dependent Variable Descriptive Statistics") %>%
  fmt_number(columns = 1:6, decimals = 4) %>%
  tab_spanner(columns = c(ER, AS, SL, WE), label = "Correlations") %>%
  tab_style(
    style = cell_borders(sides = "right"),
    locations = cells_body(columns = "Standard Deviation")
  )

Data_Frame %>%
  select(z1) %>%
  mutate(z1 = as_factor(z1)) %>%
  ggplot(aes(x = z1)) +
  stat_count() +
  ggtitle("Figure Sd: Distribution of the Uncorrelated Offset Variable") +
  theme_light()

Data_Frame %>%
  select(x1) %>%
  ggplot(aes(x = x1)) +
  stat_bin() +
  ggtitle("Figure Se: Distribution of the Uncorrelated Offset Poisson Dependent Variable") +
  theme_light()
```

The descriptive statistics for x1 are similar to SJ but shrunken given that the conceptal rate parameter/mean is now `r mean(1:10)*.1`.

In addition, all the correlations between x1 and the IVs are shrunken relative to SJ due to the reduced variance observed in x1.

### Correlated Offset Depedent Variable

This section describes the process for generating the correlated offset Poisson distributed dependent variable.

The correlated offset variable is implemented in a way similar to the uncorrelated offset variable except that the set of trials _n_ for each observation will be based on the four IVs instead of randomly sampled.

The process to create the correlated offsets began in a way similar to that of generating the underlying Normal dependent variable by sampling values for each IV as four draws from a Normal distribution with a standard deviation of .05 and the population coefficient vector used to create the underlying Normal dependent variable reflected over 0 (i.e., multipled by -1).

```{r correlated-offset-coef}
Coefficient_Vector_Offset <- 
  rnorm(4, Coefficient_Vector*-1, .05)

Coefficient_Vector_Offset %>%
  data.frame(name = namelist, value = .) %>%
  pivot_wider(everything()) %>%
  gt() %>%
  tab_header("Table S13: Sampled Offset Coefficient Values") %>%
  fmt_number(columns = 1:4, decimals = 4)
```

The offset coefficient values were used, like those from the underlying Normal dependent variable, to generate a unit, Normally distributed 'offset' variable. This 'offset' variable was then translated to a uniform distribution between 1 and 10 like the uncorrelated _n_. The translation also followed a similar procedure to how the underlying Normal dependent variable was translated into Poisson and negative Binomial variables---by translating the Normal variable to cumulative probabilities, and then subsequently, translating those probabilities into quantiles of the uniform distribution ranging from 0 to 10 taking the next highest/`ceiling` integer's value.

#... ended here... describing correlated offset...

```{r correlated-offset}
Data_Frame %<>%
  mutate(
    z2 =
      ER*Coefficient_Vector_Offset[[1]] + AS*Coefficient_Vector_Offset[[2]] + 
      SL*Coefficient_Vector_Offset[[3]] + WE*Coefficient_Vector_Offset[[4]],
    z2 = z2 + rnorm(total_n, 0, sqrt(1 - var(z2))),
    z2 = z2 %>% pnorm(log.p = TRUE) %>% 
      qunif(0, 10, log.p = TRUE) %>% ceiling(),
    x2 = J %>% pnorm(log.p = TRUE) %>% 
      qbinom(z2, .1, log.p = TRUE)
  )

Data_Frame %>%
  summarise("Mean" = mean(x2)) %>% 
  bind_cols(
    Data_Frame %>%
      summarise("Standard Deviation" = sd(x2))
  ) %>%
  bind_cols(
    Data_Frame %>% 
      cor %>% 
      as_tibble(rownames = "IV Name") %>%
      filter(`IV Name` == "x2") %>%
      select(-SJ, -J, -`IV Name`, -MJ, -x1, -z1, -x2, -z2)
  ) %>%
  gt() %>%
  tab_header("Table S14: Correlated Offset Poisson Dependent Variable Descriptive Statistics") %>%
  fmt_number(columns = 1:6, decimals = 4) %>%
  tab_spanner(columns = c(ER, AS, SL, WE), label = "Correlations") %>%
  tab_style(
    style = cell_borders(sides = "right"),
    locations = cells_body(columns = "Standard Deviation")
  )

Data_Frame %>%
  select(z2) %>%
  mutate(z2 = as_factor(z2)) %>%
  ggplot(aes(x = z2)) +
  stat_count() +
  ggtitle("Figure Sf: Distribution of the Correlated Offset Variable") +
  theme_light()

Data_Frame %>%
  select(x2) %>%
  ggplot(aes(x = x2)) +
  stat_bin() +
  ggtitle("Figure Sg: Distribution of the Correlated Offset Poisson Dependent Variable") +
  theme_light()
```

<!-- ## Zero-inflated Poisson Dependent Variable -->

<!-- The zero-inflated Poisson dependent variable uses the Poisson variable as well as the Normally distributed variable created to produce the correlated offset (negative, randomized Normal variable coefficients).  The correlated offset variable is translated through a cumulative Normal probability to a binomial quantile function with 1 draw and a probability of .9.  -->


<!-- ```{r zero-inflate} -->
<!-- Data_Frame %<>% -->
<!--   mutate( -->
<!--     Y_ZIP =  -->
<!--       Y_Poisson *  -->
<!--       qbinom( -->
<!--         pnorm(Censoring, log.p = TRUE), -->
<!--         1, .9, log.p = TRUE) -->
<!--   ) -->

<!-- Data_Frame %>% -->
<!--   select(Y_ZIP) %>% -->
<!--   ggplot(aes(Y_ZIP)) + stat_bin() -->

<!-- Data_Frame %>% -->
<!--   summarise( -->
<!--     across(.fns = mean), -->
<!--     )  -->

<!-- Data_Frame %>% -->
<!--   summarise( -->
<!--     across(.fns = sd), -->
<!--     )  -->

<!-- Data_Frame %>%  -->
<!--   cor %>%  -->
<!--   kable -->

<!-- ``` -->

```{r save-data, results='hide', include=FALSE}
saveRDS(Data_Frame, "./Data_Results/DF.rds")
```

```{r load-data, results='hide', include=FALSE}
Data_Frame <- 
  readRDS("./Data_Results/DF.rds")
```

# Primary Modeling

This section describes the model estimation and dominance analysis of the primary analysis models involving SJ and MJ variables.

This section also sets the deviance $R^2$ function (i.e., `dev_r2`) needed for dominance analysis.

```{r dev-R2}
dev_r2 <-
  function(obj) {
    res <- (1 - obj$deviance/obj$null.deviance)
    names(res) <- "dev_r2"
    return(res)
  }
```

## Poisson Regressions

This section's focus is on obtaining all modeling results associated with the PR using SJ as DV.

### Obtain Modeling Results

This section estimates and reports on the PR results. An IRR and standardized computation are also included.

These results form Table 2 of the manuscript.

```{r SJ-pois-reg}
SJ_pois_reg <- 
  glm(SJ ~ ER + AS + SL + WE, 
      data = Data_Frame, 
      family = poisson()) 

SJ_pois_reg_unstd <- 
  SJ_pois_reg %>% 
  parameters() 

SJ_pois_reg_std <- 
  SJ_pois_reg %>%
  standardise_parameters(method = "basic")

SJ_pois_reg_unstd  %>% 
  select(-df_error, -CI) %>%
  rename(Low = "CI_low", High = "CI_high") %>%
  mutate(IRR = exp(Coefficient)) %>%
  left_join(
    SJ_pois_reg_std %>% 
      select(Parameter, Std_Coefficient) %>%
      rename(Standardized = "Std_Coefficient"),
    by = "Parameter") %>%
  gt(rowname_col = "Parameter") %>%
  fmt_number(columns = 2:9, decimals = 4) %>%
  tab_spanner(columns = c(Low, High), label = "Confidence Interval") %>%
  tab_header("Table 2: Poisson Regression") %>% 
  tab_style(
    style = cell_borders(sides = "right"),
    locations = cells_body(columns = "p")
  ) %T>%
  print %>%
  gtsave(filename = "poisson_coeff.tex", path = "./includes/")
```

The results in Table 2 echo those of Table S9 in that the obtained coefficients are derived directly from the results reported on in Table S7---with a translation to a Poisson, log-linear model scale. 

### Obtain All Subsets R-square

This section captures each Poisson model subset's $R^2$ value associated with a specific set of IVs.

```{r SJ-pois-reg-subsets}
IV_subsets <- 
  expand_grid(c("ER", ""), c("AS", ""), c("SL", ""), c("WE", "")) %>%
  set_names(c("ER", "AS", "SL", "WE")) %>%
  mutate(num_per = rowSums(across(.fns = ~ str_length(.) > 1))) %>%
  arrange(num_per, desc(ER), desc(AS), desc(SL), desc(WE)) %>%
  select(-num_per) %>%
  slice(-1) %>% 
  t() %>%
  as_tibble() 

SJ_pois_subsets <-
  map_dbl(IV_subsets,
          \(ivs) {
            discard(ivs, ~ str_length(.) < 2) %>%
            reformulate(response = "SJ") %>%
              glm(data = Data_Frame, family = poisson()) %>%
              dev_r2()
          }
  )

IV_subset_names <-
  map_chr(IV_subsets, 
          \(ivs) {
            discard(ivs, ~ str_length(.) < 2) %>%
            str_c(., collapse = " + ")
          }
  )

IV_subset_names %>% 
  as_tibble() %>%
  bind_cols(SJ_pois_subsets) %>%
  set_names(c("variable", "SJ")) %>%
  gt(rowname_col = "variable") %>%
  tab_header("Table S15: All Subsets Deviance R-square Poisson Models") %>%
  fmt_number(columns = 2, decimals = 4)
```

These results help to explain the observed complete dominance results and will be used in the manuscript to demonstrate specific computations.

### Dominance Analytic Results

This section captures the dominance analytic results for the Poisson modeling.

```{r SJ-pois-DA}
SJ_pois_DA <-
  domir(SJ ~ ER + AS + SL + WE, 
        \(fml, ...) {
          res <- 
            glm(fml, ...) 
          return(dev_r2(res))
        },
        data = Data_Frame, family = poisson())

SJ_pois_DA %>% 
  pluck("General_Dominance") %>%
  as_tibble(rownames = "Variable") %>%
  left_join(SJ_pois_DA %>% 
              pluck("Standardized") %>%
              as_tibble(rownames = "Variable"),
            by = "Variable") %>%
  set_names(c("Variable", "General Dominance", "Standardized")) %>%
  gt(rowname_col = "Variable") %>%
  tab_header("Table S16: Poisson Model General Dominance Statistics") %>%
  fmt_number(columns = 2:3, decimals = 4) %>%
  tab_source_note(str_c("Overall Deviance R-square is ", 
                        SJ_pois_reg %>% dev_r2() %>% 
                          sprintf("%5.4f", .), "."))

SJ_pois_DA %>% 
  pluck("Conditional_Dominance") %>%
  as_tibble(rownames = "Variable") %>%
  set_names(c("Variable", str_c("Subset Size: ", 1:4))) %>%
  gt(rowname_col = "Variable") %>%
  tab_header("Table S17: Poisson Model Conditional Dominance Statistics") %>%
  fmt_number(columns = 2:5, decimals = 4)

SJ_pois_DA %>% 
  pluck("Complete_Dominance") %>%
  as_tibble(rownames = "Dominating Variable") %>%
  mutate(
    `Dominating Variable` = str_remove(`Dominating Variable`, "Dmnates_")
  ) %>%
  set_names(c("Dominating Variable", str_c("Dominated Variable: ", 
                                           c("ER", "AS", "SL", "WE")))) %>%
  gt(rowname_col = "Dominating Variable") %>%
  tab_header("Table S18: Poisson Model Complete Dominance Statistics") %>%
  sub_missing() %>% 
  tab_stubhead("Dominating Variable")
```

The PR-based general dominance statistics in Table S.. show that the dominance hierarchy among IVs do not show large differences as all four IVs have relatively similar general dominance statistics. This result is not unexpected given the design of the population-level effects.

The sampled results' dominance hierarchy show that AS is most important (i.e., generally dominates all others), followed by ER, then SL, and finally WE (i.e., generally dominated by all others).

The standardized values express the general dominance statistics as a proportion of the $R^2$.

The conditional dominance statistics based on the PR model reported in Table S.. add to the general dominance statistics in that AS is shown also to conditionally dominate ER and WE but _not_ SL as the size 4 results for AS and SL reverse. ER, the second most dominant, also only conditionally dominates WE given the size 4 results.  Finally, SL does not conditionally dominate WE either given the pattern change between sizes 2 and 3.

Finally, the complete dominance results in Table S.. show that the only complete dominance designation possible among the IVs is between AS and ER.

## Negative Binomial Regressions

This section's focus is on obtaining all modeling results associated with the NBR using MJ as DV.

### Obtain Modeling Results

This section estimates and reports on the NBR results. As with the PR, an IRR and standardized computation are also included. Additionally, the Theta parameter is included in a footnote.

These results form Table 3 of the manuscript.

```{r MJ-nb-reg}
MJ_nb_reg <- 
  glm.nb(MJ ~ ER + AS + SL + WE, 
      data = Data_Frame) 

MJ_nb_reg_unstd <- 
  MJ_nb_reg %>% 
  parameters() 

MJ_nb_reg_std <- 
  MJ_nb_reg %>%
  standardise_parameters(method = "basic")

MJ_nb_reg_unstd  %>% 
  select(-df_error, -CI) %>%
  rename(Low = "CI_low", High = "CI_high") %>%
  mutate(IRR = exp(Coefficient)) %>%
  left_join(
    MJ_nb_reg_std %>% 
      select(Parameter, Std_Coefficient) %>%
      rename(Standardized = "Std_Coefficient"),
    by = "Parameter") %>%
  gt(rowname_col = "Parameter") %>%
  fmt_number(columns = 2:9, decimals = 4) %>%
  tab_spanner(columns = c(Low, High), label = "Confidence Interval") %>%
  tab_header("Table 3: Negative Binomial Regression") %>% 
  tab_style(
    style = cell_borders(sides = "right"),
    locations = cells_body(columns = "p") 
  ) %>%
  tab_source_note(str_c("Theta parameter is ", 
                        MJ_nb_reg$theta %>% 
                          format(big.mark = ",", digits = 4), ".")) %T>%
  print %>%
  gtsave(filename = "nb_coeff.tex", path = "./includes/")
```

The results in Table 3 again echo those of Table S9 in that the obtained coefficients are derived directly from the results reported on in Table S7. The results are also relatively similar to Table 2 with the exception of larger values across all coefficients and a slightly different rank order of the standardized results.

### Obtain All Subsets R-square

This section captures each negative Binomial model subset's $R^2$ value associated with a specific set of IVs.

```{r MJ-nb-reg-subsets}
MJ_nb_subsets <-
  map_dbl(IV_subsets, 
          \(ivs) {
            discard(ivs, ~ str_length(.) < 2) %>%
            reformulate(response = "MJ") %>%
              glm.nb(data = Data_Frame) %>%
              dev_r2()
          }
  )

IV_subset_names %>% 
  as_tibble() %>%
  bind_cols(MJ_nb_subsets) %>%
  set_names(c("variable", "MJ")) %>%
  gt(rowname_col = "variable") %>%
  tab_header("Table S19: All Subsets Deviance R-square Negative Binomial Models") %>%
  fmt_number(columns = 2, decimals = 4)
```

As with the individual PR results, the NBR results are used for computations and explaining the pattern of complete dominance results.

### Dominance Analytic Results

This section captures the dominance analytic results for the negative Binomial modeling.

```{r MJ-nb-DA}
MJ_nb_DA <-
  domir(MJ ~ ER + AS + SL + WE, 
        \(fml, ...) {
          res <- 
            glm.nb(fml, ...) 
          return(dev_r2(res))
        },
        data = Data_Frame)

MJ_nb_DA %>% 
  pluck("General_Dominance") %>%
  as_tibble(rownames = "Variable") %>%
  left_join(MJ_nb_DA %>% 
              pluck("Standardized") %>%
              as_tibble(rownames = "Variable"),
            by = "Variable") %>%
  set_names(c("Variable", "General Dominance", "Standardized")) %>%
  gt(rowname_col = "Variable") %>%
  tab_header("Table S20: Negative Binomial Model General Dominance Statistics") %>%
  fmt_number(columns = 2:3, decimals = 4) %>%
  tab_source_note(str_c("Overall Deviance R-square is ", 
                        MJ_nb_reg %>% dev_r2() %>% 
                          sprintf("%5.4f", .), "."))

MJ_nb_DA %>% 
  pluck("Conditional_Dominance") %>%
  as_tibble(rownames = "Variable") %>%
  set_names(c("Variable", str_c("Subset Size: ", 1:4))) %>%
  gt(rowname_col = "Variable") %>%
  tab_header("Table S21: Negative Binomial Model Conditional Dominance Statistics") %>%
  fmt_number(columns = 2:5, decimals = 4)

MJ_nb_DA %>% 
  pluck("Complete_Dominance") %>%
  as_tibble(rownames = "Dominating Variable") %>%
  mutate(
    `Dominating Variable` = str_remove(`Dominating Variable`, "Dmnates_")
  ) %>%
  set_names(c("Dominating Variable", str_c("Dominated Variable: ", 
                                           c("ER", "AS", "SL", "WE")))) %>%
  gt(rowname_col = "Dominating Variable") %>%
  tab_header("Table S22: Negative Binomial Model Complete Dominance Statistics") %>%
  sub_missing() %>% 
  tab_stubhead("Dominating Variable")
```

The NBR-based DA results are quite similar to those obtained for the PR-based results. One notable exception is the importance ordering between importance SL and WE. 

In the NBR, WE generally dominates SL. No other dominance designations were possible between these IVs.

<!-- # ~~~ NB regs don't work with dominance_analysis() - method dispatch issue? -->
<!-- # ~~~ they have r2() method but DA doesn't recognize it -->
<!-- # nb_result %>% -->
<!-- #   dominance_analysis() -->

## Combined All Subsets Reporting

This section captures all PR and NBR subsets

Table 4 in the manuscript is produced in this section.

```{r comb-subsets-display}
IV_subset_names %>% 
  as_tibble() %>%
  bind_cols(SJ_pois_subsets) %>%
  bind_cols(MJ_nb_subsets) %>%
  set_names(c("variable", "Poisson/SJ", "Negative Binomial/MJ")) %>%
  gt(rowname_col = "variable") %>%
  tab_header("Table 4: All Subsets Deviance R-square Results Across Models") %>%
  fmt_number(columns = 2:3, decimals = 4) %T>%
  print() %>%
  gtsave(filename = "all_subsets.tex", path = "./includes/")
```

## Combined General Dominance Reporting

This section captures the general dominance analysis reporting.

Table 5 in the manuscript is generated in this section.

```{r gend-dom-display}
SJ_pois_DA %>% 
  pluck("General_Dominance") %>%
  as_tibble(rownames = "Variable") %>%
  left_join(MJ_nb_DA %>% 
              pluck("General_Dominance") %>%
              as_tibble(rownames = "Variable"),
            by = "Variable") %>%
  set_names(c("Variable", "Poisson/SJ", "Negative Binomial/MJ")) %>%
  bind_rows(tibble(Variable = "Overall", 
                   `Poisson/SJ` = SJ_pois_reg %>% dev_r2(), 
                   `Negative Binomial/MJ` = MJ_nb_reg %>% dev_r2())) %>%
  gt(rowname_col = "Variable") %>%
  tab_header("Table 5: General Dominance Statistics") %>%
  tab_style(
    style = cell_borders(sides = "bottom"),
    locations = cells_body(rows = 4)
  ) %>%
  fmt_number(columns = 2:3, decimals = 4) %T>%
  print %>%
  gtsave(filename = "gen_dom.tex", path = "./includes/")
```

## Conditional Dominance Graphic Reporting

This section captures the conditional dominance analysis reporting.

Figure 1 in the manuscript is generated in this section.

```{r condit-domin-display, fig.height = 3, fig.width = 4.5}
SJ_pois_DA %>%
  pluck("Conditional_Dominance") %>%
  as_tibble(rownames = "IV") %>%
  mutate(Model = "Poisson/SJ") %>%
  bind_rows(
    MJ_nb_DA %>%
      pluck("Conditional_Dominance")  %>%
      as_tibble(rownames = "IV") %>%
      mutate(Model = "Negative\nBinomial/MJ")
  ) %>%
  pivot_longer(
    cols = starts_with("subset_size"),
    names_to = "Subset Size",
    values_to = "Conditional Dominance Statistic",
    names_prefix = "subset_size_"
    ) %>% 
  mutate(
    Model = fct_relevel(Model, "Poisson/SJ", "Negative\nBinomial/MJ"),
    IV = fct_relevel(IV, "ER", "AS", "SL", "WE"),
    `Subset Size` = `Subset Size` %>% as.integer
  ) %>%
  ggplot(
    aes(x = `Subset Size`, y = `Conditional Dominance Statistic`, group = IV, color = IV)
  ) + geom_line() + 
  facet_grid(rows = vars(Model)) + theme_linedraw() +
  labs(linetype = "") + 
  #scale_linetype_manual(values = c(ER = "solid", AS = "dashed", SL = "dotdash", WE = "dotted")) +
  coord_trans(xlim = c(.9, 4.1), ylim = c(.023, .195), expand = FALSE, y = "log") + 
  theme(legend.position = c(.90, .89), legend.box.background = element_rect(color = "black"), 
        legend.title = element_blank(), legend.text = element_text(size = 7), 
        legend.key.height = unit(7, "pt"), axis.text.y = element_text(size = 7), 
        legend.margin = margin(b = .5, l = .5, r = .5)) + 
  scale_y_continuous(n.breaks = 5) + scale_color_viridis_d()

ggsave("condit_gph.png", height = 4*.75, width = 6*.75, 
       units = "in", path = "./includes/")
```

# Exposure Modeling

## Uncorrelated Exposure without Offset

### Obtain Modeling Results

```{r x1-reg-no-exp}
x1_reg_no_exp <- 
  glm(x1 ~ ER + AS + SL + WE, 
      data = Data_Frame, 
      family = poisson())

x1_reg_no_exp_unstd <- 
  x1_reg_no_exp %>% 
  parameters() 

x1_reg_no_exp_unstd %>%
  select(-df_error, -CI) %>%
  rename(Low = "CI_low", High = "CI_high") %>%
  gt(rowname_col = "Parameter") %>%
  fmt_number(columns = 2:7, decimals = 4) %>%
  tab_spanner(columns = c(Low, High), label = "Confidence Interval") %>%
  tab_header("Table S24: Uncorrelated Exposure without Offset")
```

### Dominance Analysis Results

```{r x1-DA-no-exp}
x1_no_exp_DA <-
  domir(x1 ~ ER + AS + SL + WE, 
        \(fml, ...) {
          res <- 
            glm(fml, ...) 
          return(dev_r2(res))
        },
        data = Data_Frame, family = poisson())

x1_no_exp_DA %>% 
  pluck("General_Dominance") %>%
  as_tibble(rownames = "Variable") %>%
  left_join(x1_no_exp_DA %>% 
              pluck("Standardized") %>%
              as_tibble(rownames = "Variable"),
            by = "Variable") %>%
  set_names(c("Variable", "General Dominance", "Standardized")) %>%
  gt(rowname_col = "Variable") %>%
  tab_header("Table S25: Uncorrelated Exposure with No Offset General Dominance Statistics") %>%
  fmt_number(columns = 2:3, decimals = 4) %>%
  tab_source_note(str_c("Overall Deviance R-square is ", 
                        x1_reg_no_exp %>% dev_r2() %>% 
                          sprintf("%5.4f", .), "."))

x1_no_exp_DA %>% 
  pluck("Conditional_Dominance") %>%
  as_tibble(rownames = "Variable") %>%
  set_names(c("Variable", str_c("Subset Size: ", 1:4))) %>%
  gt(rowname_col = "Variable") %>%
  tab_header("Table S26: Uncorrelated Exposure with No Offset Conditional Dominance Statistics") %>%
  fmt_number(columns = 2:5, decimals = 4)

x1_no_exp_DA %>% 
  pluck("Complete_Dominance") %>%
  as_tibble(rownames = "Dominating Variable") %>%
  mutate(
    `Dominating Variable` = str_remove(`Dominating Variable`, "Dmnates_")
  ) %>%
  set_names(c("Dominating Variable", str_c("Dominated Variable: ", 
                                           c("ER", "AS", "SL", "WE")))) %>%
  gt(rowname_col = "Dominating Variable") %>%
  tab_header("Table S27: Uncorrelated Exposure with No Offset Complete Dominance Statistics") %>%
  sub_missing() %>% 
  tab_stubhead("Dominating Variable")
```

## Uncorrelated Exposure with Offset

### Obtain Modeling Results

```{r x1-reg-exp}
x1_reg_exp <- 
  glm(x1 ~ ER + AS + SL + WE + offset(log(z1)), 
      data = Data_Frame, 
      family = poisson())

x1_reg_exp_unstd <- 
  x1_reg_exp %>% 
  parameters() 

x1_reg_exp_unstd %>%
  select(-df_error, -CI) %>%
  rename(Low = "CI_low", High = "CI_high") %>%
  gt(rowname_col = "Parameter") %>%
  fmt_number(columns = 2:7, decimals = 4) %>%
  tab_spanner(columns = c(Low, High), label = "Confidence Interval") %>%
  tab_header("Table S27: Uncorrelated Exposure with Offset")
```

### Dominance Analysis Results

```{r x1-DA-exp}
x1_exp_DA <-
  domir(x1 ~ ER + AS + SL + WE, 
        \(fml, ...) {
          res <- 
            fml %>%
            update(. ~ . + offset(log(z1))) %>%
            glm(...) 
          return(dev_r2(res))
        },
        data = Data_Frame, family = poisson())

x1_exp_DA %>% 
  pluck("General_Dominance") %>%
  as_tibble(rownames = "Variable") %>%
  left_join(x1_no_exp_DA %>% 
              pluck("Standardized") %>%
              as_tibble(rownames = "Variable"),
            by = "Variable") %>%
  set_names(c("Variable", "General Dominance", "Standardized")) %>%
  gt(rowname_col = "Variable") %>%
  tab_header("Table S28: Uncorrelated Exposure with Offset General Dominance Statistics") %>%
  fmt_number(columns = 2:3, decimals = 4) %>%
  tab_source_note(str_c("Overall Deviance R-square is ", 
                        x1_reg_exp %>% dev_r2() %>% 
                          sprintf("%5.4f", .), "."))

x1_exp_DA %>% 
  pluck("Conditional_Dominance") %>%
  as_tibble(rownames = "Variable") %>%
  set_names(c("Variable", str_c("Subset Size: ", 1:4))) %>%
  gt(rowname_col = "Variable") %>%
  tab_header("Table S29: Uncorrelated Exposure with Offset Conditional Dominance Statistics") %>%
  fmt_number(columns = 2:5, decimals = 4)

x1_exp_DA %>% 
  pluck("Complete_Dominance") %>%
  as_tibble(rownames = "Dominating Variable") %>%
  mutate(
    `Dominating Variable` = str_remove(`Dominating Variable`, "Dmnates_")
  ) %>%
  set_names(c("Dominating Variable", str_c("Dominated Variable: ", 
                                           c("ER", "AS", "SL", "WE")))) %>%
  gt(rowname_col = "Dominating Variable") %>%
  tab_header("Table S30: Uncorrelated Exposure with Offset Complete Dominance Statistics") %>%
  sub_missing() %>% 
  tab_stubhead("Dominating Variable")
```

## Combined Uncorrelated Exposure Model Reporting

```{r x1-reg-table}
x1_reg_no_exp_unstd %>% 
  select(Parameter, Coefficient) %>%
  mutate(IRR = exp(Coefficient)) %>%
  left_join(
    x1_reg_exp_unstd %>% 
      select(Parameter, Coefficient) %>%
      rename(Coefficient_e = "Coefficient") %>%
      mutate(IRR_e = exp(Coefficient_e)),
    by = "Parameter") %>%
  gt(rowname_col = "Parameter") %>%
  fmt_number(columns = 2:5, decimals = 4) %>%
  tab_header("Table 6: Uncorrelated Exposure Poisson Regression") %>% 
  cols_label(Coefficient_e = "Coefficient", IRR_e = "IRR") %>%
  tab_spanner(columns = c("Coefficient", "IRR"), label = "No Offset") %>%
  tab_spanner(columns = c("Coefficient_e", "IRR_e"), label = "Offset")

#%T>%
  print %>%
  gtsave(filename = "uncorr_exp_coeff.tex", path = "./includes/")
```

## Wrong Poisson C

```{r}
poisson_result_cens_wrong <- 
  glm(Y_Poisson_Censored ~ IV1 + IV2 + IV3 + IV4, data = Data_Frame, 
      family = poisson())

poisson_result_cens_wrong %>% 
  parameters()

poisson_result_cens_wrong %>%
  standardise_parameters(method = "basic")

domir(Y_Poisson_Censored ~ IV1 + IV2 + IV3 + IV4, 
      \(fml,...) {
        res <- glm(fml, ...) 
        ret <- r2(res)[[1]]
      }
      ,
      data = Data_Frame, family = poisson()) 
```

## Right Poisson C

```{r}
poisson_result_cens_right <- 
  glm(Y_Poisson_Censored ~IV1 + IV2 + IV3 + IV4 + offset(log(N_obs_censor)), data = Data_Frame, 
      family = poisson())

poisson_result_cens_right %>% 
  parameters()

poisson_result_cens_right %>%
  standardise_parameters(method = "basic")

domir(Y_Poisson_Censored ~ IV1 + IV2 + IV3 + IV4, 
      \(fml,...) {
        fml2 <- update(fml, . ~ . + offset(log(N_obs_censor)))
        res <- glm(fml2, ...) 
        ret <- r2(res)[[1]]
      }
      ,
      data = Data_Frame, family = poisson()) 
```

<!-- # Zero-Inflation -->

<!-- ```{r} -->
<!-- zip_result <-  -->
<!--   zeroinfl(Y_ZIP ~ IV1 + IV2 + IV3 + IV4 | IV1 + IV2 + IV3 + IV4,  -->
<!--            data = Data_Frame) -->

<!-- zip_result %>%  -->
<!--   parameters() -->

<!-- zip_result %>% -->
<!--   standardise_parameters(method = "basic") -->
<!-- ``` -->

<!-- ## IV DA -->

<!-- ```{r} -->
<!-- domir(Y_ZIP ~ IV1 + IV2 + IV3 + IV4,  -->
<!--       \(fml,...) { -->
<!--         fml2 <- update(fml, . ~ .) -->
<!--         res <- zeroinfl(fml2, ...)  -->
<!--         ret <- r2(res)[[1]] -->
<!--       } -->
<!--       , -->
<!--       data = Data_Frame)  -->
<!-- ``` -->

# Records and Reproducibility

```{r}
sessionInfo()
```

The random seed information used in this session:

    84490856
    Min: 1, Max: 99999999
    2022-08-14 14:50:02 UTC
    Random.org
