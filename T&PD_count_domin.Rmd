---
title: "Count Regression Model Dominance Analysis"
author: "Joseph Luchman"
subtitle: Analysis Documentation in Support of Manuscript
output:
  html_document:
    df_print: paged
editor_options:
  markdown:
    wrap: 72
---

This notebook provides documentation for the generation of the data used
in the manuscript **Relative Importance Analysis for Count Regression
Models**.

This document extends on the main manuscript by focusing more closely on
implementation details. These implementation details are are not
essential for the reader to understand the manuscript but are essential
for reproducibility of the results. The details in this notebook also
add additional context to the manuscript's analyses by, for example,
extending the Poisson regression results reported to negative Binomial
regression.

Details on the random seed as well as the details of the R environment
are available at the end of this notebook.

```{r set-up, include = FALSE}
library(gt)
library(MASS)
library(tidyverse)
library(domir)
library(parameters)
library(performance)
library(datawizard)
library(MCMCpack)
library(ggeffects)

set.seed(84490856)
```

# Data Generation

The manuscript describes four survey scales that will 
be used in the analysis as independent variables. 
These independent variables are:

a.  cognitive ability or intelligence (*ability*)
b.  solution motivation (*motivation*)
c.  tactfulness (*tact*)
d.  rhetorical skill (*skill*)

My approach in generating the independent variable data for 
this manuscript was to begin
by developing higher-order population parameters that would produce a
specific result from a linear regression. The data as generated were
only to be based loosely on this higher-order conceptual structure and
the population parameters actually used to generate the data were
sampled, and thus varied, from it in a way that was not intended to be
directly under my control. As such, the results would follow from the
higher order conceptual structure imposed on the data but not be
completely determined by me.

## Generate Independent Variable Data

The generation of the four independent variables began with setting 
up a higher-order population-level covariance matrix of four widget-maker 
independent variables. This
higher-order variance-covariance matrix was to be applied as a parameter
for data generation in an inverse Wishart variate generating function as
the scale matrix parameter.

### Higher-Order Variance-Covariance Structure

The variances chosen were four equally-spaced values between standard
deviation values of 1 and 2. 
The first independent variable, *ability*, had a
$\sigma_{ability} = 1.00$ and $\sigma^2_{ability} = 1.00$. 
The second independent variable, *motivation*,
had $\sigma_{motivation} = 1.33$ and $\sigma^2_{motivation} = 1.78$. 
*tact* had
$\sigma_{tact} = 1.67$ and $\sigma^2_{tact} = 2.78$. 
Finally, *skill* had
$\sigma_{skill} = 2.00$ and $\sigma^2_{skill} = 4.00$.

The covariances values chosen were "balanced" across 
independent variables such that the
total redundancy for any one independent variable was identical 
to the others. The six
correlations between the four independent variables were 
designed to take on one of three
values .250, .125, and .063 with the following values specified between
each of the specific independent variables: 
$r_{ability,motivation} = .250$, 
$r_{ability,tact} = .125$,
$r_{ability,skill} = .063$, 
$r_{motivation,tact} = .063$, 
$r_{motivation,skill} = .125$, and
$r_{tact,skill} = .250$.

The code block below constructs and reports on the correlation matrix as
well as the the variance-covariance matrix on which it is based.

```{r gen-iv-mat}
namelist <- c("ability", "motivation", "tact", "skill")

Covariance_Matrix <- 
  c(1, 
    .5^(2:4)*sqrt(1*c((4/3)^2, (5/3)^2, 4))*sqrt(1),
    .5^2*sqrt(1)*sqrt(1*(4/3)^2), 
    (4/3)^2, 
    .5^(4:3)*sqrt(1*(4/3)^2)*sqrt(1*c((5/3)^2, 4)),
    .5^(3:4)*sqrt(1*(5/3)^2)*sqrt(1*c(1, (4/3)^2)), 
    (5/3)^2, 
    .5^2*sqrt(1*(5/3)^2)*sqrt(1*4),
    .5^(4:2)*sqrt(1*4)*sqrt(1*c(1, (4/3)^2, (5/3)^2)), 
    4) |>
  matrix(nrow = 4, byrow = TRUE, dimnames = list(namelist, namelist))

Covariance_Matrix |> 
  as.data.frame() |>
  gt(rownames_to_stub = TRUE) |>
  tab_header("Table S1: Higher-order Population Covariance Matrix") |>
  fmt_number(columns = 2:5, decimals = 4)

Covariance_Matrix |> 
  cov2cor() |> 
  as.data.frame() |>
  gt(rownames_to_stub = TRUE) |>
  tab_header("Table S2: Higher-order Population Correlation Matrix")
```

### Sampled Population Parameter Values

The population parameters for use in generating data were sampled as one
draw from an inverse Wishart distribution with the higher-order
variance-covariance matrix as the scale parameter and a degrees of
freedom parameter of 100. The large value for the degrees of freedom was
chosen as it has the effect of reducing the variances of each element of
the sampled matrix which stabilizes the correlations of the values
sampled to be closer to the scale matrix's values.

The code block below takes the variance-covariance matrix sample and
reports on the sampled values as well as the correlation matrix of the
sampled values.

```{r sample-iv-mat}
Covariance_Matrix_Use <- riwish(100, Covariance_Matrix)*100

Covariance_Matrix_Use |> 
  as.data.frame() |>
  gt(rownames_to_stub = TRUE) |>
  tab_header("Table S3: Sampled Population Covariance Matrix") |>
  fmt_number(columns = 2:5, decimals = 4)

Covariance_Matrix_Use |> 
  cov2cor() |> 
  as.data.frame() |>
  gt(rownames_to_stub = TRUE) |>
  tab_header("Table S4: Sampled Population Correlation Matrix") |>
  fmt_number(columns = 2:5, decimals = 4)
```

Note that the sampled variance-covariance matrix is multiplied by 100 as
it has values that are around $1/100$ of the values of the original
matrix due to the degrees of freedom parameter.

### Generate Observed Data

The analysis data were generated as random draws from a Multivariate
Normal distribution using the sampled population parameters in the
previous step as a variance-covariance matrix.

The number of observations in the sample was also determined using a
single draw from a random uniform distribution that was required to
range between 5,000 and 10,000. This range of observations that was
chosen as it should allow for stable estimates from these data yet be
within a range observed of many large social surveys.

The code block below samples the sample size value and takes all independent variable
samples. The block also reports on descriptive statistics from the
sampled independent variable observations including the sample size.

```{r gen-iv-data, message=FALSE}
total_n <- 
  runif(n = 1, min = 5000, max = 10000) |> 
  round()

Data_Frame <- 
  mvrnorm(n = total_n, 
          mu = rep(0, times = 4), 
          Sigma = Covariance_Matrix_Use) |> 
  as.data.frame() |>
  set_names(namelist)

Data_Frame |>
  summarise(
    across(everything(), .fns = mean),
    ) |> 
  pivot_longer(everything(), names_to = "Independent Variable Name", values_to = "Mean") |>
  left_join(
  Data_Frame |>
  summarise(
    across(everything(), .fns = sd),
    ) |> 
    pivot_longer(
      everything(), 
      names_to = "Independent Variable Name", 
      values_to = "Standard Deviation"
    )
  ) |>
  left_join(
    Data_Frame |> 
      cor() |> 
      as_tibble(rownames = "Independent Variable Name")
  ) |>
  gt(rowname_col = "Independent Variable Name") |>
  tab_header("Table S5: Sampled Data Descriptive Statistics") |>
  fmt_number(columns = 2:7, decimals = 4) |>
  tab_spanner(columns = c(ability, motivation, tact, skill), label = "Correlations") |>
  tab_style(
    style = cell_borders(sides = "right"),
    locations = cells_body(columns = "Standard Deviation")
  ) |>
  tab_source_note(
    str_c(
      "Sample Size of Simulated Data is ", 
      nrow(Data_Frame) |> 
        format(big.mark = ","), 
      "."
    )
  )
```

## Generate Dependent Variables

This section creates multiple count dependent variables from a single Normally
distributed dependent variable. The Normally distributed dependent variable is generated first and is
then used to determine the values of other count dependent variables. This method is
used as it allows more control over the magnitudes of relationships
between the count dependent variable's with the independent variables.

### Generate Normally Distributed Dependent Variable

The generation of the Normally distributed variable extended from the
methodology that was established above where a set of higher-order
population parameters are first set and adjusted using a draws from a
specific distribution to reduce the effect of my decisions on the
results.

Conceptually, the underlying Normally distributed variable can be
thought of as a latent propensity each tailoring shop has for making
more garments. This garment propensity variable (called $propense$) is
generated as a linear combination of the four tailoring shop independent variables. In
devising the higher-order population coefficients, I thought it would be
convenient to generate coefficients that, when combined with the
higher-order population variances, would produce a specific $R^2$ under
idealized conditions. In generating these coefficients, I intentionally
ignored the higher-order population covariances to allow this section to
be easier to follow and because I was not so much trying to attain a
specific $R^2$ in the observed data but rather to have a reasonable,
systematic approach to generating independent variable coefficient values.

#### Higher-Order Population Parameters

The approach used to generate the higher-order independent variable coefficient values was
to devise values such that the coefficients achieve an $R^2 = .12$. I
also wanted to assign the coefficient values in a way such that no
single independent variable contributed more to the $R^2$ than any other. The simplest way
to do so was to ignore the independent variable covariances and use the
$R^2 = \sum\beta^2\sigma^2$ formula for computing the $R^2$ to work
backward to obtain a value that ascribes each independent variable a contribution of .04.
Given the population variances, the values chosen were:
$\beta_{ability} =.20$, $\beta_{motivation} =.15$, $\beta_{tact} =.12$,
$\beta_{skill} =.10$.

The code block below sets the higher order independent variable coefficient population
parameters and reports on their values.

```{r pop-coefs}
Coefficient_Vector <- c(.2, sqrt(.04/(4/3)^2), sqrt(.04/(5/3)^2), .1)

Coefficient_Vector |>
  data.frame(name = namelist, value = _) |>
  pivot_wider(id_cols = everything()) |>
  gt() |>
  tab_header("Table S6: Higher-order Population Coefficient Values") |>
  fmt_number(columns = 1:4, decimals = 4)
```

#### Sampled Population Parameters

The higher-order population values were used as the means in four draws
from a Normal distribution each with a standard deviation of .05 to
obtain coefficients. As the higher-order coefficient parameters were all
within a relatively narrow range, the standard deviation of .05 allowed
for the possibility that, by chance, the rank ordering of coefficient
magnitudes could change.

The code block below implements the sampling of the coefficient values
and reports on their values.

```{r sampled-coeff}
Coefficient_Vector_Use <- rnorm(4, Coefficient_Vector, .05)

names(Coefficient_Vector_Use) <- namelist

Coefficient_Vector_Use |>
  data.frame(name = namelist, value = _) |>
  pivot_wider(id_cols = everything()) |>
  gt() |>
  tab_header("Table S7: Sampled Population Coefficient Values") |>
  fmt_number(columns = 1:4, decimals = 4)
```

The sampled population coefficients varied from the higher-order values
and varied from the higher-order coefficients' rank order as
$\beta_{skill} > \beta_{tact}$ in the sampled values whereas the reverse was
true of the higher-order values.

#### Generate Observed Normal Distribution Variable Values

The garment propensity variable $propense$ was generated as a linear
combination of the four tailoring shop characteristics and their
respective coefficients. The error variance for $propense$ was set to be
$1 - \sigma^2_{ability\beta_{ability} + motivation\beta_{motivation} + tact\beta_{tact} + skill\beta_{skill}}$
thus forcing the variance of $propense$ to be 1. The mean of $propense$ is also set
to be 0.

The code block below generates and reports on the descriptive statistics
of $propense$.

```{r gen-y-normal}
Data_Frame <- 
  Data_Frame |>
  mutate(
    propense = 
      ability*Coefficient_Vector_Use[["ability"]] + 
      motivation*Coefficient_Vector_Use[["motivation"]] + 
      tact*Coefficient_Vector_Use[["tact"]] + 
      skill*Coefficient_Vector_Use[["skill"]], 
    propense = propense + rnorm(total_n, 0, sqrt(1 - var(propense)))
  )

Data_Frame |>
  summarise("Mean" = mean(propense)) |> 
  bind_cols(
    Data_Frame |>
      summarise("Standard Deviation" = sd(propense))
  ) |>
  bind_cols(
    Data_Frame |> 
      cor() |> 
      as_tibble(rownames = "Independent Variable Name") |>
      filter(`Independent Variable Name` == "propense") |>
      select(-propense, -`Independent Variable Name`)
  ) |>
  gt() |>
  tab_header("Table S8: Garment Propensity Descriptive Statistics") |>
  fmt_number(columns = 1:6, decimals = 4) |>
  tab_spanner(columns = c(ability, motivation, tact, skill), label = "Correlations") |>
  tab_style(
    style = cell_borders(sides = "right"),
    locations = cells_body(columns = "Standard Deviation")
  )
```

In addition, a histogram of $propense$ is reported.

```{r y-gph, message=FALSE}
Data_Frame |>
  select(propense) |>
  ggplot(aes(x = propense)) +
  stat_bin() +
  ggtitle("Figure Sa: Distribution of the Garment Propensity Variable") +
  theme_light()
```

Finally, a regression predicting $propense$ using the four tailoring shop independent variables
is estimated and reported on below to confirm that the sampled
population coefficient values are re-obtainable in the data.

```{r y-regress}
lm(propense ~ ., data = Data_Frame) |> 
  parameters() |>
  select(-df_error, -CI) |>
  rename(Low = "CI_low", High = "CI_high") |>
  gt(rowname_col = "Parameter") |>
  fmt_number(columns = 2:7, decimals = 4) |>
  tab_spanner(columns = c(Low, High), label = "Confidence Interval") |>
  tab_header("Table S9: Garment Propensity Linear Regression")
```

The results confirm that the coefficients are recoverable in the data.

### Generate Poisson Dependent Variable

The Poisson distributed variable related to the number of sport jackets
produced (i.e., $solution$) was based on the garment propensity variable and
translated to the Poisson distribution using the cumulative propensity
to quantile method described above.

$solution$ was given a mean of 1 was chosen to make the $solution$ results as close
to those from $propense$ as possible; using this approach both dependent variables will have
variances of 1.

The code block below implements the translation process and reports on
the descriptive results.

```{r gen-y-poisson}
Data_Frame <-
  Data_Frame |> 
  mutate(
    solution = 
      propense |> 
      pnorm(log.p = TRUE) |> 
      qpois(1, log.p = TRUE)
  )

Data_Frame |>
  summarise("Mean" = mean(solution)) |> 
  bind_cols(
    Data_Frame |>
      summarise("Standard Deviation" = sd(solution))
  ) |>
  bind_cols(
    Data_Frame |> 
      cor() |> 
      as_tibble(rownames = "Independent Variable Name") |>
      filter(`Independent Variable Name` == "solution") |>
      select(-solution, -propense, -`Independent Variable Name`)
  ) |>
  gt() |>
  tab_header("Table S10: Poisson Dependent Variable Descriptive Statistics") |>
  fmt_number(columns = 1:6, decimals = 4) |>
  tab_spanner(columns = c(ability, motivation, tact, skill), label = "Correlations") |>
  tab_style(
    style = cell_borders(sides = "right"),
    locations = cells_body(columns = "Standard Deviation")
  )
```

In addition, a histogram of $solution$ is provided below.

```{r pois-gph, message=FALSE}
Data_Frame |>
  select(solution) |>
  ggplot(aes(x = solution)) +
  stat_count() +
  ggtitle("Figure Sb: Distribution of the Poisson Dependent Variable") +
  theme_light()
```

### Generate Negative Binomial Dependent Variable

The negative Binomial distributed variable related to the number of
overcoats produced (i.e., $OC$) was also based on the garment propensity
variable translated to the negative Binomial distribution using the
cumulative propensity to quantile method.

The generation of the $OC$ also sought to ensure as much similarity to
the $propense$ variable as possible while also requiring that $OC$'s
distribution fail to meet the assumptions of the Poisson distribution.
The quantile function values that $propense$ was translated into were then a
*size* parameter of .5 and *mu* parameter of 1.

This combination of *size* and *mu* parameters result in a mean (i.e.,
the *mu*/$\mu$ value) of 1 but a variance that substantially exceeded 1;
in this case or a value of 3 as $\sigma^{2} = \mu + \frac{\mu^2}{size}$.

The code block below implements the translation process and reports on
the descriptive results.

```{r gen-y-neg-bin}
Data_Frame <-
  Data_Frame |>
  mutate(
    OC = propense |> 
      pnorm(log.p = TRUE) |> 
      qnbinom(size = .5, mu = 1, log.p = TRUE)
  )

Data_Frame |>
  summarise("Mean" = mean(OC)) |> 
  bind_cols(
    Data_Frame |>
      summarise("Standard Deviation" = sd(OC))
  ) |>
  bind_cols(
    Data_Frame |> 
      cor() |> 
      as_tibble(rownames = "Independent Variable Name") |>
      filter(`Independent Variable Name` == "OC") |>
      select(-solution, -propense, -`Independent Variable Name`, -OC)
  ) |>
  gt() |>
  tab_header("Table S11: Negative Binomial Dependent Variable Descriptive Statistics") |>
  fmt_number(columns = 1:6, decimals = 4) |>
  tab_spanner(columns = c(ability, motivation, tact, skill), label = "Correlations") |>
  tab_style(
    style = cell_borders(sides = "right"),
    locations = cells_body(columns = "Standard Deviation")
  )
```

In addition, a histogram of $OC$ is provided below.

```{r neg-bin-gph, message=FALSE}
Data_Frame |>
  select(OC) |>
  ggplot(aes(x = OC)) +
  stat_count() +
  ggtitle("Figure Sc: Distribution of the Negative Binomial Dependent Variable") +
  theme_light()
```

## Report Primary Generated Data Descriptive Statistics

This section produces Table 4 in the manuscript including the
descriptive statistics for all four independent variables and the $solution$ dependent variable reported on in
the manuscript.

```{r display-observed-descriptives}
table_4 <-
Data_Frame |>
  summarise(across(everything(), mean)) |>
  pivot_longer(everything(), names_to = "Variable", values_to = "Mean") |>
  left_join(
    Data_Frame |>
      summarise(across(everything(), sd)) |>
      pivot_longer(everything(), names_to = "Variable", 
                   values_to = "Standard Deviation"),
    by = "Variable"
  ) |>
  left_join(
    Data_Frame |> 
      cor() |> 
      as_tibble(rownames = "Variable"),
    by = "Variable"
  ) |>
  filter(!(Variable %in% c("propense", "OC"))) |>
  select(-propense, -OC) |>
  gt() |>
  tab_header("Table 4: Descriptive Statistics") |>
  fmt_number(columns = 2:8, decimals = 4) |>
  tab_spanner(columns = c(ability, motivation, tact, skill, solution), label = "Correlations") |>
  tab_style(
    style = cell_borders(sides = "right"),
    locations = cells_body(columns = "Standard Deviation")
  )
  
table_4 |>
  print()

table_4 |>
  gtsave(filename = "descrips_initial.tex", path = "./includes/")
```

# Primary Modeling

This section describes the model estimation and dominance analysis of
the primary analysis models involving the primary $solution$ and the
unreported $OC$ dependent variables.

## Modeling Relationship Problem Solutions Production

All modeling and reporting of $solution$ is implemented in this section.

### Obtain Modeling Results

The code block below estimates, formats, and reports on the Poisson
regression with $solution$.

These results are used in Table 5 of the manuscript.

```{r solution-pois-reg}
solution_pois_reg <- 
  glm(solution ~ ability + motivation + tact + skill, 
      data = Data_Frame, 
      family = poisson()
      ) 

solution_pois_param <- 
  solution_pois_reg |> 
  parameters() 

table_5 <- 
  solution_pois_param  |> 
  select(-df_error, -CI, -z, -p) |>
  (\(df) bind_rows(slice_tail(df, n = 4), slice_head(df, n = 1)))() |>
  rename(Low = "CI_low", High = "CI_high", 
         B = "Coefficient", `\\sigma_{B}` = "SE") |>
  mutate(`e^B` = exp(B), 
         Parameter = str_replace(Parameter, "\\(Intercept\\)", "Intercept")) |>
  gt(rowname_col = "Parameter") |>
  fmt_number(columns = 2:6, decimals = 4) |>
  tab_spanner(columns = c(Low, High), label = "95% Confidence Interval") |>
  tab_header("Table 5: Poisson Regression Predicting Relationship Problem Solutionss Produced")

table_5 |>
  print()

table_5 |>
  gtsave(filename = "poisson_coeff.tex", path = "./includes/")
```

Below the marginal effects from the $solution$ model are depicted in a
graphic.

```{r solution-pois-mgn}
map(c("ability", "motivation", "tact", "skill"),
    \(iv) {
      
      lst <- 
        list(-2:2) |>
        set_names(iv)
      
      solution_pois_reg |>
        emmeans::emmeans(reformulate(iv), 
                         at = lst) |>
        as_tibble() |>
        rename(mgn = all_of(iv)) |>
        mutate(var = iv |> 
                 as_factor(),
               emmean = exp(emmean))
    }
) |>
  list_rbind() |>
  ggplot(aes(x = mgn, y = emmean, group = var, color = var)) + 
  geom_line() + scale_color_viridis_d() + theme_light() + 
  ylab("Predicted Counts") + xlab("Values of Tailoring Characteristic") + 
  labs(color = "Tailoring\nCharacteristic") + 
  ggtitle("Figure Sd: Marginal Effects of the Relationship Problem Solutions\nProduction Model")
```

### Obtain All Submodels' R-squares

The code block below captures all sub-model $R^2_{DEV}$ values. The
values obtained in this section are used in Table 6 of the manuscript.

```{r solution-pois-reg-subsets}
IV_subsets <- 
  expand_grid(c("ability", ""), c("motivation", ""), c("tact", ""), c("skill", "")) |>
  set_names(c("ability", "motivation", "tact", "skill")) |>
  mutate(
    num_per = rowSums(
      across(everything(), .fns = \(x) str_length(x) > 1)
    )
  ) |>
  arrange(num_per, desc(ability), desc(motivation), desc(tact), desc(skill)) |>
  select(-num_per) |>
  slice(-1) |> 
  t() |>
  as_tibble() 

solution_pois_subsets <-
  map_dbl(IV_subsets,
          \(ivs) {
            discard(ivs, \(x) str_length(x) < 2) |>
              reformulate(response = "solution") |>
              glm(data = Data_Frame, family = poisson()) |>
              r2_kullback(adjust = FALSE)
          }
  )

IV_subset_names <-
  map_chr(IV_subsets, 
          \(ivs) {
            discard(ivs, ~ str_length(.) < 2) |>
              str_c(collapse = " + ")
          }
  )

table_6 <- 
  IV_subset_names |> 
  (\(nms) str_c("solution ~ ", nms))() |>
  as_tibble() |>
  bind_cols(solution_pois_subsets) |>
  gt() |>
  tab_header("Table 6: R^2_{DEV} by Sub-model") |>
  fmt_number(columns = 2, decimals = 4) |>
  cols_label(everything() ~ "")

table_6 |>
  print()

table_6 |>
  gtsave(filename = "all_subsets.tex", path = "./includes/")
```

### Dominance Analytic Results

The code block below implements the dominance analysis using $solution$.

```{r solution-pois-DA}
solution_pois_DA <-
  domir(solution ~ ability + motivation + tact + skill, 
        \(fml, ...) {
          res <- 
            glm(fml, ...) 
          return(r2_kullback(res, adjust = FALSE))
        },
        data = Data_Frame, family = poisson()
  )

solution_pois_DA |> 
  pluck("General_Dominance") |>
  as_tibble(rownames = "Variable") |>
  left_join(solution_pois_DA |> 
              pluck("Standardized") |>
              as_tibble(rownames = "Variable"),
            by = "Variable") |>
  set_names(c("Variable", "General Dominance", "Standardized")) |>
  gt(rowname_col = "Variable") |>
  tab_header("Table S12: Poisson Model General Dominance Statistics") |>
  fmt_number(columns = 2:3, decimals = 4) |>
  tab_source_note(
    str_c("Overall Deviance R-square is ", 
          solution_pois_reg |> 
            r2_kullback() |> 
            (\(r2) sprintf("%5.4f", r2))(), 
          "."
    )
  )

solution_pois_DA |> 
  pluck("Conditional_Dominance") |>
  as_tibble(rownames = "Variable") |>
  set_names(c("Variable", str_c("Subset Size: ", 1:4))) |>
  gt(rowname_col = "Variable") |>
  tab_header("Table S13: Poisson Model Conditional Dominance Statistics") |>
  fmt_number(columns = 2:5, decimals = 4)

solution_pois_DA |> 
  pluck("Complete_Dominance") |>
  as_tibble(rownames = "Dominating Variable") |>
  mutate(
    `Dominating Variable` = str_remove(`Dominating Variable`, "Dmnates_")
  ) |>
  set_names(c("Dominating Variable", str_c("Dominated Variable: ", 
                                           c("ability", "motivation", "tact", "skill")))) |>
  gt(rowname_col = "Dominating Variable") |>
  tab_header("Table S14: Poisson Model Complete Dominance Designations") |>
  sub_missing() |> 
  tab_stubhead("Dominating Variable")
```

The code block below generates and reports on Table 7 in the manuscript.

```{r gend-dom-display}
table_7 <- 
  solution_pois_DA |> 
  pluck("General_Dominance") |>
  as_tibble(rownames = "Variable") |>
  gt(rowname_col = "Variable") |>
  tab_header("Table 7: General Dominance Statistics") |>
  cols_label(everything() ~ "") |>
  fmt_number(columns = 2, decimals = 4)

table_7 |>
  print()

table_7 |>
  gtsave(filename = "gen_dom.tex", path = "./includes/")
```

The Figure 1 in the manuscript is also produced below.

```{r condit-domin-display, fig.height = 3, fig.width = 4.5}
solution_pois_DA |>
  pluck("Conditional_Dominance") |>
  as_tibble(rownames = "Independent Variable") |>
  pivot_longer(
    cols = starts_with("subset_size"),
    names_to = "Subset Size",
    values_to = "Conditional Dominance Statistic",
    names_prefix = "subset_size_"
    ) |> 
  mutate(
    IV = fct_relevel(IV, "ability", "motivation", "tact", "skill"),
    `Subset Size` = 
      `Subset Size` |> 
      as.integer()
  ) |>
  ggplot(
    aes(x = `Subset Size`, y = `Conditional Dominance Statistic`, 
        group = IV, color = IV)
  ) + geom_line() + 
  theme_linedraw() +
  labs(linetype = "") + 
  coord_trans(xlim = c(.9, 4.1), ylim = c(.015, .185), expand = FALSE, y = "log") +
  theme(legend.position = c(.90, .89), 
        legend.box.background = element_rect(color = "black"), 
        legend.title = element_blank(), legend.text = element_text(size = 7), 
        legend.key.height = unit(7, "pt"), axis.text.y = element_text(size = 7), 
        legend.margin = margin(b = .5, l = .5, r = .5),
        axis.title = element_text(family = "serif")
  ) + 
  scale_y_continuous(n.breaks = 5) + scale_color_viridis_d()

ggsave("condit_gph.png", height = 4*.75, width = 6*.75, 
       units = "in", path = "./includes/")
```

## Modeling Overcoat Production

All modeling and reporting of $OC$ is implemented in this section.

Ultimately, these results were not included in the manuscript as they
did not meaningfully extend on the Poisson regression results. They are
included here for completeness.

### Obtain Modeling Results

The code block below estimates, formats, and reports on the negative
Binomial regression with $OC$. The Theta parameter is included in a
footnote.

```{r OC-nb-reg}
OC_nb_reg <- 
  glm.nb(OC ~ ability + motivation + tact + skill, 
      data = Data_Frame) 

OC_nb_param <- 
  OC_nb_reg |> 
  parameters() 

OC_nb_param  |> 
  select(-df_error, -CI, -z, -p) |>
  (\(df) bind_rows(slice_tail(df, n = 4), slice_head(df, n = 1)))() |>
  rename(Low = "CI_low", High = "CI_high", B = "Coefficient") |>
  mutate(`e^B` = exp(B), 
         Parameter = str_replace(Parameter, "\\(Intercept\\)", "Intercept")) |>
  gt(rowname_col = "Parameter") |>
  fmt_number(columns = 2:6, decimals = 4) |>
  tab_spanner(columns = c(Low, High), label = "95% Confidence Interval") |>
  tab_header("Table S15: Negative Binomial Regression") |> 
  tab_source_note(
    str_c("Theta parameter is ", 
          OC_nb_reg$theta |> 
            format(big.mark = ",", digits = 4), ".")
  )
```

Below the marginal effects from the $OC$ model are depicted in a
graphic.

```{r OC-nv-mgn}
map(c("ability", "motivation", "tact", "skill"),
    \(iv) {
      
      lst <- 
        list(-2:2) |>
        set_names(iv)
      
      OC_nb_reg |>
        emmeans::emmeans(
          reformulate(iv), 
          at = lst
        ) |>
        as_tibble() |>
        rename(mgn = all_of(iv)) |>
        mutate(var = iv |> 
                 as_factor(),
               emmean = exp(emmean))
    }
) |>
  list_rbind() |>
  ggplot(aes(x = mgn, y = emmean, group = var, color = var)) + 
  geom_line() + scale_color_viridis_d() + theme_light() + 
  ylab("Predicted Counts") + xlab("Values of Tailoring Characteristic") + 
  labs(color = "Tailoring\nCharacteristic") + 
  ggtitle("Figure Se: Marginal Effects of the Overcoat\nProduction Model")
```

### Dominance Analytic Results

The code block below implements the dominance analysis using $OC$.

```{r OC-nb-DA}
OC_nb_DA <-
  domir(OC ~ ability + motivation + tact + skill, 
        \(fml, ...) {
          res <- 
            glm.nb(fml, ...) 
          return(r2_kullback(res, adjust = FALSE))
        },
        data = Data_Frame)

OC_nb_DA |> 
  pluck("General_Dominance") |>
  as_tibble(rownames = "Variable") |>
  left_join(OC_nb_DA |> 
              pluck("Standardized") |>
              as_tibble(rownames = "Variable"),
            by = "Variable") |>
  set_names(c("Variable", "General Dominance", "Standardized")) |>
  gt(rowname_col = "Variable") |>
  tab_header("Table S16: Negative Binomial Model General Dominance Statistics") |>
  fmt_number(columns = 2:3, decimals = 4) |>
  tab_source_note(
    str_c("Overall Deviance R-square is ", 
          OC_nb_reg |> 
            r2_kullback(adjust = FALSE) |> 
            (\(r2) sprintf("%5.4f", r2))(), 
          ".")
  )

OC_nb_DA |> 
  pluck("Conditional_Dominance") |>
  as_tibble(rownames = "Variable") |>
  set_names(c("Variable", str_c("Subset Size: ", 1:4))) |>
  gt(rowname_col = "Variable") |>
  tab_header("Table S17: Negative Binomial Model Conditional Dominance Statistics") |>
  fmt_number(columns = 2:5, decimals = 4)

OC_nb_DA |> 
  pluck("Complete_Dominance") |>
  as_tibble(rownames = "Dominating Variable") |>
  mutate(
    `Dominating Variable` = str_remove(`Dominating Variable`, "Dmnates_")
  ) |>
  set_names(c("Dominating Variable", str_c("Dominated Variable: ", 
                                           c("ability", "motivation", "tact", "skill")))) |>
  gt(rowname_col = "Dominating Variable") |>
  tab_header("Table S18: Negative Binomial Model Complete Dominance Designations") |>
  sub_missing() |> 
  tab_stubhead("Dominating Variable")
```

# Records and Reproducibility

```{r records-repro}
sessionInfo()
```

The random seed information used in this session:

```         
84490856
Min: 1, Max: 99999999
2022-08-14 14:50:02 UTC
Random.org
```
